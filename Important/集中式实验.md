# 问题说明
`Meta-ITD`和`Meta-AID`中，在`valid`和`test`中更新`y`，使用的是自定义优化器进行手动更新。
```python
learner = copy.deepcopy(self.head)  
for param in learner.parameters():  
    param.data = param.data.clone().detach().requires_grad_(True)  
opt_learner = torch.optim.Adam(learner.parameters(), lr=lr)  
for n in range(adaptation_steps):  
    opt_learner.zero_grad()  
    adaptation_error = self.criterion(learner(self.feature(test_adaptation_data)),  
                                      test_adaptation_labels)  
    if n < (adaptation_steps - 1):  
        adaptation_error.backward(retain_graph=True)  
    else:  
        adaptation_error.backward()  
    opt_learner.step()
```

这样做是因为，当使用和`train`部分一样的`MAML.adapt()`时会由于显存爆炸而导致运行不了几步，且显存随迭代步数而迅速、大量增加，故放弃。----由此也导致`MAML`和`ANIL`方法一开始跑不了，只能用手动更新的方法（但效果一般，远不如网络上提供的该有的`baseline`效果）。
如下`train`部分内循环更新相关代码：
```python
learner = self.head.clone()  
for n in range(adaptation_steps):  
    train_adaptation_error = self.criterion(learner(self.feature(train_adaptation_data)),  
                                            train_adaptation_labels)  
    learner.adapt(train_adaptation_error)
```

研究了`l2l GitHub issue`后，发现有人遇到同样问题`CUDA out of Memory`。按照说明，将`valid`和`test`更新部分改为:
```python
for step in range(adaptation_steps):  
    adaptation_error = self.criterion(learner(valid_adaptation_data), valid_adaptation_labels)  
    learner.adapt(adaptation_error, first_order=True)
```

根据`Doc`说明，这样的话使用的就是一阶梯度信息(**`FOMAML`**)进行参数更新。---------不会出现显存和时间的问题，且效果非常好。

# 疑惑
1. 为何使用`adapt()`的效果会明显好于手动梯度更新
2. 若是因为`adapt()`计算了二阶梯度导致了显存问题，那么在`train`部分，同样没有显示地声明使用`adapt(*,first_order=True)`,为何没有出现所谓的显存问题?


# 0616
1. 时间复杂度对比：
   四个Benchmark中，不同算法达到相同validation accuracy所需要的训练时间
2. 空间复杂度对比：
   四个Benchmark中，不同算法在一次训练iteration中的所需要的最大显存占用
3. CIFAR-FS上MetaAID算法准确率的优化


# 0618
1. 重新仔细回顾 AID、TID
   * [x] ITD, AID的详细计算（表达式推导）过程
   * [ ] 补充到 #HyperGradient 
2. 根据 1. 改正 MetaAID 算法实现
   * 查看了ITD中backward()后feature参数的梯度信息，以及AID中CG_Centralized函数里grad_f_x的值，发现二者相等----》说明grad_f_x的计算依旧使用了历史信息，这也解释了为什么目前AID方法内存比ITD还多、时间还慢。
   * [x] 在内循环的每次迭代中：
     使用`feature_output = self.feature(train_adaptation_data).detach()`，参与内循环。-----设置`self.feature`的参数属性
     ```python
     for p in self.feature.parameters():  
	    p.requires_grad = False
	  ```
	  有效降低了内存耗费，时间耗费，在f_loss相同的情况下，AID中grad_f_x和ITD中backward所得的feature参数梯度不一样---》证明二者计算方式不同

# 0704
1. 准确率提升
   a. 增加迭代步数----**可行**，目前在所有Benchmark上都是迭代1000次
   b. 更换为更加复杂的网络，如Resnet。
      尝试了多个Resnet网络，从头训练效果均不好。深层次网络提取到的特征维度很大，如Resnet12 backbone提取到的embedding维度为16K, 使用当前的训练范式的话，在每次adaptation时，线性层需要做一个16K->ways的转换，导致训练非常困难。尝试更换单层线性层：
      * [ ] 在线性层之前，增加一个降维模块（PCA，或者瓶颈层）
      * [ ] 使用原型网络(已有文献)。基于度量学习：根据support set 中的数据和标签，构建class-average embedding，在query set中计算输入embedding和各class-average embedding 的欧氏距离或余弦相似度，应用Softmax得到类别概率。
		【如何训练：根据query set计算得到的Loss，反向传播，更新backbone参数】---不再是基于梯度的元学习
		另：l2l提供了使用Resnet12和CNN4的预训练模型，使用的是普通的有监督学习，利用原型网络进行少样本验证。
      * [ ] 对embedding进行凸优化。普通分类器与SVM，RR等结合，进行凸优化---已有文献MetaOptNet】---AID 用不了
	   
   c. Top-k accuracy。准确率提升非常明显（可达20％）使用的意义是什么。。。
   d. 数据增强。尝试了对FC100进行数据增强，validation acc和test acc 基本没变化。
2. 相同步数下，不同学习率对学习效果的影响对比。
   内循环步数设置为20.（经验证，在内循环学习率固定的情况，一定范围内的步数越多，结果越好。---内循环的结果准确性对超梯度的计算结果有很大影响）
   测试mini-ImageNet上，两种方法，横轴：[1e-4, 1e-3, 1e-2, 1e-1]。纵轴：测试准确率。
   结果：MetaAID在前三个学习率下，表现稳定，MetaITD只在第一个学习率下保持稳定。
3. 空间复杂度。
   与学习率无关，只与网络，batch_size, 图像大小，内循环步数有关。
   以mini-ImageNet为例，横轴：[5,10,15,20]内循环步数，纵轴：两种方法在同一运行环境下的所耗费的稳定内存
   结果：MetaITD耗费内存随内循环步数线性增长，且远大于MetaAID所耗费内存。
4. 时间复杂度。
   选取两个算法的最优超参数（经过网格搜索得到），在四个Benchmark上对比MetaITD与MetaAID的两个指标（相同运行环境下）
   a. 单步迭代所耗费时间对比
   b. 将最高验证准确率（两种方法中的Max）的`0.9（可调）`，作为目标准确率。将两种方法的验证准确率平滑后（移动平均，窗口大小为`3（可调）`），计算各自稳定达到目标准确率（该点及该点后`5(可调)`个点均不小于）所耗费的总时间。

# 0707
* [ ] Fig.1 单栏，四个Benchmark，Validation Acc v.s. iteration（平滑处理/采样），删掉 MetaITD
* [ ] Fig.2 单栏 四个Benchmark，Test Acc v.s. inner steps，不带MetaITD
    `---（MAML中只有regression部分使用了，image classification部分直接使用图表展示结果）`
* [ ] 删掉超参数table
* [ ] Table.1 单栏/双栏，四个Benchmark，Test Acc, `mean ± std`

Discussion
* [ ] Fig.3 MiniImageNet，学习率鲁棒性与Test Acc，(增加MAML和ANIL方法?)
      `原论文有推荐的learning rate`
* [x] Fig.4 MiniImageNet，空间复杂度与Inner Steps，(增加MAML与ANIL方法?)
      `原论文有推荐的inner Steps`
* [x] Table.2 四个Benchmark， **时间复杂度**，两个维度指标，增加MAML与ANIL


# 0720
* [x] AAAI 会议要求，投稿格式整理
* [x] 论文整理，细节检查
    1. Abstract 需要分段吗
    2. 对于内存优势的阐述(Abstract+正文)
* [x] 论文实验部分说明完善
* [x] 增加Word中对集中式文献的引用
* [ ] 算法能否用于小样本实验之外的学习任务，大的数据集，ImageNet.


# 1016
* [ ] 增加imagenet，Metadataset数据集上的对比实验
    存在问题：
    1. 大数据集图片种类多，需要足够深的网络去提取特征，在元训练时，单个任务中支持集内的样本类别少，当仍然采用线性分类头时，会出现线性头输入的embedding维度和输出维度差距太大，难以优化。
       * 常见的一个方法是，采用基于metric的分类器，基于support set中样本的高维embedding构建类protocol，这样在query set中，基于输入embedding和protocol的距离比较（余弦/欧几里得），得出prediction，进而计算loss和Accuracy。按照这样的方法，则下层的损失函数似乎可以不存在（原来可以通过梯度下降的方法调整不断调整线性层的参数；如果使用support set内**全部的样本**进行原型计算，如过没有后续的优化处理，则不存在原型的调整）。如此，MAML，ANIL，ITD-BiO一类方法可以直接更换分类头且不需要存储下层的优化轨迹，而MetaAID方法依赖于下层函数的强凸性和损失函数，此时的下层决定变量对应的是原型embedding，无法求解下层损失函数对它的倒数。
       * 在基类上进行预训练，得到一个好的特征提取器，再利用基于metric的方法，构建原型，完成在新任务上的预测。这一套思路和方法，不仅简单而且实现了FSL中的SOTA，并且可以扩展到大数据集如ImageNet。见`2020ICLR A Baseline for Few-Shot Image Classification`和`2021CVPR Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning`。后者将预训练特征提取+metric-based元学习结合起来，从base class和novel class角度分析元学习在小样本学习中的效果。
       * 先尝试使用Resnet训练miniImageNet，cifar。MAML、ANIL可以成功使用Resnet12 训练miniImageNet。MetaITD模式和ANIL类似，区别在于outer loop是否对head进行更新，尝试减小inner step，设置学习率和ANIL接近---可以达到与ANIL近似的效果。三种方法的$\log{loss}$在0.2左右，才会出现较为明显上升趋势。
         将MetaAID中的hg更新换为evaluation_loss的直接backward(), 效果好转，loss下降曲线接近MetaITD、ANIL，但仍然不及MAML。说明超梯度估计偏差大，猜测可能是Softmax引入了非凸性，导致原来的setting失效，但是这样的话为何采用CNN4时不会出现这样的情况。
         另一种方案，是采用目前的先进的小样本学习方法，在训练集上先进行有监督学习预训练，再进行元学习阶段的训练。
	 * [ ] 尝试更换Resnet18模型
	   和Resnet12效果相同，hg更新梯度时无法训练起来，替换为backward()则可以训练（超参数一致），模型层数的增加使得训练难以进行？
	 * [x] 更换数据集为imagenet后，MetaAID可以跑通
	 * [ ] 待解决问题：
	    1. MetaITD测试准确率很低，远高于验证准确率，但是两者选用的数据集一样，猜测问题原因可能出现在test_lr设置，尝试设置低一点。
	    2. MAML缺少lr低的训练，目前基本没有训练起来
	    3. MetaAID准确率表现不如ANIL和MetaITD，效果的最好的是替换hg为backward
	       * 尝试减小inner_step变为10---无明显改进；
	       * 减小CG_step---15效果差不多，10失败；
	       * 尝试增大CG_step---30效果一般
	       * 增大meta_lr---一般；
	    1. MetaAID没有保存模型，缺少test准确率
* [ ] 
   