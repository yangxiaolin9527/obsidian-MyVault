* [x] Deterministic和Stochastic双层优化的核心区别；在元学习背景下的使用
	1. formulation
		2019 ICML meta-learning tutorial
		![[Pasted image 20240505164405.png]]
		下层：given $x$,一个少样本ML过程，在给定任务$T_i$的$\mathcal{D}^{tr}$上训练出$y^*$。$y^*$在该任务的$\mathcal{D^{ts}}$上表现衡量了先验$x$的好坏。
		上层：目标是从大量、多样任务中学习一个先验（模拟人脑学习），这些任务的数据不一样，但是在某种程度上具有类似的架构/结构。希望这个先验在这些任务上的表现都很好，优化形式为最大化概率 和/平均 或最小化损失 和/平均。
	2. stochastic
	   在few-shot背景下，下层优化作为一个ML过程，面对的一个完整的训练任务，在参数更新中，使用的是全部样本的梯度信息。可以使用deterministic bilevel optimization algorithm。
		![[Pasted image 20240505191248.png]]
	   这里的$m$是全部的任务数，同时也是**task sampling batch size**
	   $\widetilde{w}^{*}$本身没有现实意义，为了方便描述上层目标函数
	   
	   当$m$很大时，为了高效训练，设置**task sampling batch**，引入了随机性。
	   ![[Pasted image 20240505192106.png]]
					   **each outer iteration optimization**
* [x] 实验部分，超参数设置
    不同于普通的ML，直接训练出一个好的模型，测试数据直接送入模型即可得到结果。
    Meta Learning学习到的相当于是一个预训练模型，在测试集上，首先需要在`support set`上进行`fast adaptation`，这就涉及到一个问题，在对比不同的元学习算法时，该过程的超参数设置(如`lr`,`adaptation steps`)是否需要相同。
    
	1. **不相同理由**: "our training procedure is based on a simple machine learning principle: test and train conditions must match"--Meta-Learning tutorial
	    不同的算法学习方式不同。以论文中各为例，`ANIL`内循环只更新y，外循环同时更新y和x;`MAML`内外循环对x,y都进行更新；`MetaITD`和`MetaAID`在内循环只更新y，外循环只更新x。
	    不同的参数更新方式（学习方式），设置的超参数应该因算法而异。
    2. **相同理由**: 这些元学习的算法的本质都是`feature reuse`,对比不同算法实际上就是对比学习到特征好坏，在测试时，可以`freezing backbone`,只学习`head`，进而采用相同的超参数设置更新y,从而公平地比对不同算法学习到的特征。
* [x] 实验部分补齐
* [x] Conclusion部分
* [x] Abstract部分
* [x] 收敛性分析，$\kappa$和$\Theta(\kappa)$的来源，推导
    * $\Theta(\kappa)$表示的算法复杂度的渐进确界
    * $\mathcal{O}(\kappa)$表示的是算法复杂度的最坏情况，即复杂度渐进上界
* [x] 复杂度分析，引入采样后复杂度变化
* [x] Introduction 最后部分
	复杂度描述怎么写，最后一段检查



# 0808
* [x] Algorithm 2 -> Algorithm 1，检查正文和图表中
* [x] 图重新画，注意算法名，顺序，颜色，caption
* [x] 表格中对backbone添加脚注；可添加，\label warning
* [x] Fig 命名问题，MetaITD命名问题
* [x] parameter 单复数问题
* [x] 实验部分，步长设置相关描述 （doubling...）
* [x] Contribution 3部分，$\epsilon^{-1}$复杂度的文献 (MAML,ANIL,iMAML ?)
* [x] Related work中 （文献）提出了AID方法用于解决元学习问题
* [x] 内存对比图，caption miniImageNet/tieredImageNet，CIFAR-FS和FC100
* [x] 时间复杂度表格，单列，单栏？ caption部分删除
* [x] 文献引用格式检查 (arXiv，misc)
* [x] 证明部分，格式整理，$\mu$和$\mu_g$,全部统一为$\mu$?，$l_{f,0}$和$l_{f0}$
* [x] $\sigma^{2}_{fg}=?$
    ![[Pasted image 20240811193459.png]]
* [x] 增加文献
* [x] 嵌套循环，文献引用，修改upper-level optimization/problem lower-level optimization/problem; inner-loop iterations, outer-loop iterations
* [x] 文献过多，控制在2页内
* [x] 参考文献中引用arXiv数量过多，找替代的，增加AAAI的
* [x] 语言描述上前后统一，如 meta-learning和meta learning
* [x] 附录的实验部分，补充完整
* [x] 附录完成后，分开
* [ ] 摘要中: `can converge to an exact optimal solution`换成`can converge to an exact solution`, meta-learning/meta learning 替换，upper-level iteration/optimization 替换。
* [x] 整理代码，匿名链接，README
* [x] Checklist 完善
* [ ] 语法格式错误，纠正：单复数问题（如parameters）,\cite与\citet用法，bilevel programming与bilevel optimization。


# 0813
## Introduction to our code
Our code is organized into four sections with the same names as the datasets, each corresponding to the experiments conducted on different datasets as described in the paper. Each section includes implementations of all comparison algorithms on the respective dataset, as well as the recording of relevant metrics, such as `meta-learning accuracy`, `memory costs`, and `wallclock time`.
## Environments for meta-learning experiments
As stated in our paper, our meta-learning experiments were conducted based on the `learn2learn` third-party library, which provides the utilities and unified interface for data preparation and implementations of the MAML and ANIL methods. Additionally, we used the `swanlab` third-party library for logging and recording metrics during the experiments. The following are the key dependency tools and packages, along with their versions, used in our experiments. They are compatible with both Windows and Linux operating systems.
* python=3.8
* torch=1.10.0
* torchvision=0.11.1
* CUDA=11.3
* learn2learn=0.1.5
* swanlab=0.3.0
## How to run our code
In each section, the experiments can be launched from the `main` file in an IDE or executed from the command line with parameters. The following are the key parameters and their meanings.
* '-t' or '--test_num': Identifier for different algorithms.
* '-s' or '--seed': Setting for the random seed.
* '-p' or '--pretrain': Whether to load a pretrained model.
* '-i' or '--iterations': Outer-loop iteration number.
* '-n' or '--test_only': Whether to only conduct fine-tuning during the testing phase.
Additionally, other important parameters, such as the size of the task batch and the setup of few-shot tasks (e.g., 'ways' and 'shots'), can be manually adjusted in the `main` file.
