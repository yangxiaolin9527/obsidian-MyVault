# 科研进展报告(40%)
## 科研进展现状
随着信息技术的飞速发展和网络的广泛普及，网络安全问题日益突出，对国家安全、经济发展和社会稳定构成了严重威胁。与此同时，人工智能（AI）技术，特别是深度学习（DL），在诸多领域取得了革命性进展，并在网络安全领域展现出巨大潜力。因此博士课题研究目标立足于AI+security，包括使用AI作为工具解决安全问题的`AI for Security`和AI本身的安全性`Security of AI`。
到现在为止，在校阶段的研究工作聚焦于课题：“基于内存优化的元学习算法研究和安全应用”，结合人工智能和优化知识的理论创新并尝试应用于安全领域。
### 问题调研和初步探索
研究初期，我们对当前深度学习在安全领域中应用的局限性进行了调研。一个突出的问题是，传统的基于深度学习的应用需要大量的标注数据，而实际的数据服从长尾分布，在样本少的情形下常常表现不佳。例如，入侵检测系统（IDS）是重要的网络安全设备，通常部署在网络内部，通过模式匹配和异常检测对网络流量进行监测和警报。基于深度学习的IDS可以从历史数据中学习到流量的统计特征，从而能够有效识别已知类型的网络攻击。但是随着攻击技术的不断演进，许多0-day攻击和APT攻击层出不穷，难以获得足够多的标注数据进行训练，使得传统的DL-based IDS存在着泛化能力差，适应性弱的缺点，这实际上是人工智能领域中经典的**小样本学习问题**。元学习，特别是基于优化的元学习如MAML、ANIL等，因为其具备快速适应新任务的特性，被认为是解决小样本问题的有效途径。然而，这类方法在实际应用中，普遍存在着计算和内存开销大的问题，因为这些方法都依赖直接的反向传播进行超梯度的计算，但是这个计算过程会存储历史的下层梯度信息。这个特性导致内存消耗随着内层优化迭代次数增大而显著增长，使得它们在资源受限场景下（如边缘物联网设备）的应用变得困难。
### 现有方案的局限性分析及研究切入点
针对上述问题，我们对现有的一些改进方法进行了分析，例如FOMAML等一阶方法通过忽略二阶导数信息来降低计算量，但是这种简化以牺牲学习精度为代价。一些基于双层优化的算法也被提出试图解决该问题，它们将下层最优解条件视为上层问题的约束来求解单层优化问题，但是这种方法不适用于下层问题规模较大或者问题复杂时；最近一些基于隐式微分的方法也被提出，但是这类方法要求下层优化具有共同的最优解，这在利用异构多任务学习的元学习实际问题中也很难满足。因此，设计一种降低存储和计算负担，又不以牺牲过多性能为代价，适用于异构任务场景下的元学习算法，是该问题的研究目标和切入点。核心在于如何高效且尽可能准确地估计超梯度，并减少或避免大量的历史信息存储。
### 算法基本思路分析与设计
考虑如下一个标准的元学习问题，它具有双层优化的形式：
$$
\begin{equation}
\begin{aligned}
&\min_{\theta \in \mathbb{R}^{p}}\,F(\theta)=\mathbb{E}_{\mathcal{T}_{i}\sim\mathcal{P}(\mathcal{T})}[f_{i}(\theta,\phi_{i}^*(\theta))],\\
&\textrm{s.t.}\quad \phi_{i}^*(\theta)=\underset{\phi\in \mathbb{R}^{q}}{\text{argmin}}~g_{i}(\theta,\phi).
\end{aligned}
\end{equation}
$$
训练/优化的目标是从服从分布$\mathcal{P}(T)$的一系列任务中学习一个通用的先验知识/元参数$\theta$,在每个具体任务$\mathcal{T}_i$上，基于该先验，模型在面对少量新数据时可以调整自身的参数$\phi_i$从而达到快速适应的目的。其中，$f_{i}(\theta,\phi)\triangleq\frac{1}{|\mathcal{D}_{i,f}|}\sum_{j=1}^{|\mathcal{D}_{i,f}|}\mathcal{L}(\theta, \phi; \xi_{i,f}^{j})$，$g_{i}(\theta,\phi)\!\triangleq\!\frac{1}{|\mathcal{D}_{i,g}|}\sum_{j=1}^{|\mathcal{D}_{i,g}|}\mathcal{L}(\theta, \phi; \xi_{i,g}^{j})+R(\phi)$，前者是模型在$\mathcal{T}_i$中query set上的平均损失，后者是模型在$\mathcal{T}_i$中support set上的带L2正则项的平均损失。
同时，给定元学习系列中的标准假设，上层目标函数$F(\theta)$是非凸的，下层$g_i(\theta, \phi)$是关于$\phi$的$\mu$-强凸函数。
事实上，在实际的工程应用中，由于资源受限和更好地训练，我们通常采用`mini-batch`的形式进行训练。因此我们将上述优化问题引入随机性，重新表述为如下形式：
$$
\begin{equation}
\begin{aligned}
&\min_{\theta \in \mathbb{R}^{p}} F_{\mathcal{B}}(\theta)=f_{\mathcal{B}}\left(\theta, \boldsymbol{\phi}^*(\theta)\right)=\frac{1}{|\mathcal{B}|}\sum_{i=1}^{|\mathcal{B}|}f_{i}(\theta,\phi_{i}^*(\theta)),\\
&\textrm{s.t.}\quad \phi_{i}^*(\theta)=\underset{\phi \in \mathbb{R}^{q}}{\text{argmin}}~g_{i}(\theta, \phi).
\end{aligned}
\end{equation}
$$
通常采用基于梯度的迭代方法求该问题的解析解，难点在于如何求上层目标函数的超梯度。常见的方法是采用迭代微分的方法进行超梯度估计，具体来说，先进行一个`K`步的内循环迭代获取对$\phi_i^{*}$的良好估计$\phi_i^{K}(\theta)$，接着使用如下公式估计超梯度：
$$
\begin{flalign}
&\frac{\partial f_{\mathcal{B}}(\theta, \boldsymbol{\phi}^{K}(\theta))}{\partial \theta}=
\frac{1}{|\mathcal{B}|}\sum_{i=1}^{|\mathcal{B}|}\frac{\partial f_{i}(\theta,\phi_{i}^{K}(\theta))}{\partial \theta}\nonumber\\
&=\frac{1}{|\mathcal{B}|}\sum_{i=1}^{|\mathcal{B}|}\left(\nabla_{\theta}f_{i}(\theta,\phi_{i}^{K}(\theta))-\lambda_{\phi}\sum_{k=0}^{K-1}\nabla_{\theta\phi}^{2}g_{i}(\theta,\phi_{i}^{k}(\theta))\times\right.\nonumber\\
&\left.\quad\prod_{q=k+1}^{K-1}\left(I\!-\!\lambda_{\phi}\nabla_{\phi}^2g_{i}(\theta,\phi_{i}^{q}(\theta))\right)\nabla_{\phi}f_{i}(\theta,\phi_{i}^{K}(\theta))\right).
\end{flalign}
$$
这也是反向传播内部所做的工作。可以看出，该估计超梯度的方法依赖于历史的梯度信息，并且随着内循环步数的增大，存储和计算成本呈线性增加。但下层问题复杂度增加时，为了更加精确地估计$\phi_i^{*}$,需要更加多步数的迭代，由此将不可避免地需要增加存储和计算资源，除此以外，长距离的反向传播链还可能造成梯度爆炸和梯度消失的问题。
我们从随机双层优化领域中得到启发，使用如下公式计算超梯度：
$$
\begin{flalign}
\nabla F_{\mathcal{B}}(\theta)&= \nabla_{\theta}f_{\mathcal{B}}(\theta, \boldsymbol{\phi}^*(\theta))-
\frac{1}{|\mathcal{B}|}\sum_{i=1}^{|\mathcal{B}|}\left(
\nabla_{\theta\phi}^2g_{i}(\theta, \phi_{i}^*(\theta))\right.\nonumber\\
&\left.\quad \times [\nabla_{\phi}^{2}g_{i}(\theta, \phi_{i}^*(\theta))]^{-1}\nabla_{\phi}f_{i}(\theta, \phi_{i}^*(\theta))\right).
\end{flalign}
$$
从上式中可以看出，计算该超梯度存在两个计算难点，分别是Hessian矩阵的逆和Jacobin矩阵，在数据维度大的场景下基本上无法直接计算，因此，我们直接对矩阵向量的积进行估计和计算。
![[hypergradient.bmp]]
如图所示，我们用$v_i^*$来表示精确的Hessian-vector product，如果可以估计$v_i^{*}$,之后就可以进一步地计算Jacobian-vector product。由此将超梯度的计算复杂度从$\mathcal{O}(q^2)$或$\mathcal{O}(pq)$降低至$\mathcal{O}(max\{p,q\})$。我们按照该思路介绍所设计的算法。
首先是用于估计$v_i^{*}$的子程序。
![[Pasted image 20250529160716.png]]
求解Hessian-vector product这样的二次规划问题等价于求解如下的最优化问题:
$$
\begin{equation}
\min_{v\in \mathbb{R}^{q}}\varphi(v),\quad\varphi(v_{i})=\frac{1}{2}v_{i}^{T}H_{i}v_{i}-b_{i}^{T}v_{i}.
\end{equation}
$$
受到共轭梯度法在求解二次规划问题中的线性加速能力，我们采用基于热启动的共轭随机梯度方法，经过$N$步迭代后得到近似解$v_{i,t}^{N}$,接着就可以基于下式进行超梯度的估计。
$$
\begin{equation}
\nabla\widehat{F}_{\mathcal{B}}(\theta_t)=\nabla_{\theta}f_{\mathcal{B}}(\theta_{t},\boldsymbol{\phi}_{t}^{K})-\frac{1}{|\mathcal{B}|}\sum_{i=1}^{|\mathcal{B}|}
\nabla_{\theta\phi}^2g_{i}(\theta, \phi_{i,t}^{K})v_{i,t}^{N}.
\end{equation}
$$
接下来是完整的内存降低的元学习算法。
![[Pasted image 20250529160702.png]]
每次进入一个新的迭代$t$，采样一个任务batch，进入任务$i$的迭代后，采用热启动策略加速迭代。进入下层优化，在**不记录梯度信息的前提下**进行$K$步迭代逼近下层最优解，在运行Subroutine1得到$v_{i,t}^{N}$后，计算并累计Jacobian-vector product。结束任务迭代后，使用超梯度估计公式计算超梯度并进行上层元参数的更新。
### 理论分析和收敛性证明
如前所述，我们构建的元学习范式是一个上层非凸、下层强凸的双层优化问题，我们给定在基于优化元学习的标准假设包括上下层相关函数的Lipschitz连续性，梯度的无偏性和有界方差。
*假设1：上层函数$F$关于$\theta$是非凸的，下层函数$g$关于$\phi$是$\mu$-强凸的。*
*假设2：定义$f(\theta, \phi)\triangleq\mathbb{E}_{\mathcal{T}_{i}\sim\mathcal{P}(\mathcal{T})}[f_{i}(\theta,\phi)]$，$g(\theta,\phi)\triangleq\mathbb{E}_{\mathcal{T}_{i}\sim\mathcal{P}(\mathcal{T})}[g_{i}(\theta,\phi)]$
	  1): $f$,$\nabla f$,$\nabla g$,$\nabla _{\theta\phi}^2g$和$\nabla_{\phi}^2g$是Lipschitz连续的
	  2): 梯度$\nabla f_i(\theta,\phi)$,$\nabla_{\phi}^2g_i(\theta, \phi)$是无偏的，且具有有限方差。
假设3：在确定性元学习情况下，即在每个外循环迭代中加载所有的训练数据，$f_i$,$\nabla f_i$,$\nabla g_i$,$\nabla _{\theta\phi}^2g_i$和$\nabla_{\phi}^2g_i$是Lipschitz连续的。*
我们在上述假设前提下进行收敛性和计算复杂度分析：
* 收敛性证明：分别针对随机性和确定性两种场景，推导算法的收敛性。在随机设定下，证明算法的次线性收敛速率以及收敛误差随任务采样大小的依赖关系。类似地，在确定性场景下证明了算法可以以次线性速率收敛。和相关工作的不同之处同时也是证明的难点在于，如何处理因任务$T_i$对应着不同下层最优参数$\phi_i^{*}$所带来的异构性。
* 计算复杂度分析：分别针对随机性和确定性两种场景，量化算法达到$\epsilon$-解所需的梯度计算复杂度。
### 实验设计和实施
为了真实评估算法的实际效果，我们设计并实施了一系列对比实验。为了全面对比其他元学习算法，我们在多个标准的小样本元学习图像分类benchmarks（CIFAR-FS, FC100, miniImageNet, tieredImageNet）上进行测试。在网络架构层面，我们遵循标准的元学习问题设定，选择4-layer CNN的网络，使用交叉熵作为损失函数，下层决策变量为模型最后的线性分类头，上层决策变量对应剩下层的模型参数，由此也满足了理论分析中下层强凸，上层非凸等设定和假设。在对比算法上选取了主流的MAML，ANIL和最近一种基于迭代微分的双层优化算法（ITD-BiO)作为Baseline，并根据对应的文献对各自算法的超参数进行调优。在评价方式上，我们选取了多维度指标进行评估，重点包括学习准确率、泛化性能，内存消耗和学习效率等。
## 阶段性科研成果
该课题工作在基于内存减少元学习算法的设计、理论分析和实验评估方面取得了如下阶段性成果。
1. 提出了一种新颖的内存降低的元学习算法。
	受随机双层优化领域启发，设计创新的超梯度估计策略，实现了在元学习过程中对计算和内存的优化，核心机制在于内循环中无需记录历史下层梯度梯度信息，仅仅使用最终迭代结果参与超梯度的估计。在面对超梯度估计公式中的大规模矩阵计算问题时，我们结合共轭梯度思想设计了一个子程序，迭代求解二次规划问题，将计算复杂度从$\mathcal{O}(pq)或\mathcal{O}(q^2)$降低到了$\mathcal{O}(max\{p,q\})$。
2. 针对所设计算法建立了严格的收敛性理论和复杂度分析。
    * 在假设1和假设2的条件下，我们给出了随机型元学习场景下算法的收敛性结果，即如下定理1：
	   *存在正整数$K_0$和$N_0$，使得当$K\ge K_0$,$N\ge N_0$时，算法1的迭代结果$\theta_t$满足：*
	$$
	\begin{equation}
	\frac{1}{T+1}\!\sum_{t = 0}^{T}\mathbb{E}[{\left\|\nabla F_{\mathcal{B}}
	(\theta_{t})\right\|}^ {2}] \!\leq\! \mathcal{O}\left(\frac{1}{T}\right)+\mathcal{O}\left(\frac{1}{|\mathcal{B}|}\right).
	\end{equation}
	$$
		该结果表明了我们的算法随着迭代次数$T$次线性收敛，并且随着任务采样大小次线性收敛。基于定理1，我们还给出了算法1在计算复杂度方面的引理:
		*对于任意$\epsilon>0$,算法1最多需要$\mathcal{O}((3+2K_0)|\mathcal{B}\epsilon^{-1}|)$次关于$\phi$的梯度计算，$\mathcal{O}((1+K_0|\mathcal{B}|)\epsilon^{-1})$次关于$\theta$的梯度计算从而获得一个$\epsilon$-解。*
		结果表明该算法的计算复杂度和MAML，ANIL等元学习算法的结果相匹配，而我们的算法同时还具有内存上的优势。
	* 在假设1和假设3的条件下，我们给出了确定型元学习场景下算法的收敛性结果，即如下定理2：
		*如果迭代次数$K\ge \mathcal{O}(\kappa)$, $N\ge \mathcal{O}(\sqrt{\kappa})$，其中$\kappa=\frac{l_g}{\mu}$，是和下层目标函数相关的常数，算法1的迭代结果$\theta_t$满足：*
	$$
	\begin{equation}
	\frac{1}{T+1}\!\sum_{t = 0}^{T}\mathbb{E}[{\left\|\nabla F
	(\theta_{t})\right\|}^ {2}] \!\leq\! \mathcal{O}\left(\frac{1}{T}\right).
	\end{equation}
	$$
		该结果表明当我们的算法可以在确定性元学习场景下以次线性速率收敛。类似地，我们还可以得到复杂度方面的结果，在该场景下，算法1最多需要$\mathcal{O}(\kappa\epsilon^{-1})$次关于$\theta$和$\phi$的梯度计算，这与最近基于迭代微分的元学习算法结果相匹配。
3. 在标准小样本图像分类数据集上进行了充分的实验评估。
	我们在四个广泛使用的小样本元学习基准图像分类数据集上多维度、综合评估了我们提出的算法。
	* 学习精度和泛化性能
	  评估元学习算法的学习性能包括两个方面，一个是在元训练阶段的准确率评估，另一个是在元测试阶段的泛化能力评估。下图1中展示了各算法在不同benchmarks的验证集上表现。
	  ![[Pasted image 20250530105745.png]]
	  结果表明我们提出的算法相较于现有元学习baseline算法在多种数据集上的优势。为了评估各算法在新任务上的泛化能力（该任务包含模型在训练阶段未“见到”过的图像），我们将元训练得到的最佳模型通过20步梯度下降微调，并记录它们在测试任务上的准确率表现，结果总结在下表中。
	  ![[Pasted image 20250530105814.png]]
	  结果显示通过我们的算法元学习到的模型相较于同类算法的具有更好的泛化性能，可以更好地适应新任务。
	* 内存成本
	  在基于优化的元学习算法中，很大一部分内存开销来自于内循环中对历史下层梯度信息的存储从而用于超梯度计算。我们对比了在不同内循环迭代次数下，不同算法在两大类型数据集上的内训消耗，结果如下图所示。
	  ![[Pasted image 20250530110458.png]]
	  结果表明，我们的算法随着内循环步数的增大，内存消耗基本不变，而其他依赖迭代微分的算法所需的内存会随内循环步数增大呈线性增长，这与我们的理论分析相吻合。特别地，即使将内循环次数设为5，我们算法的内存消耗依然相较于其他的算法要低$50$%以上。
	* 训练效率
	  一般认为，训练效率直接体现在算法的收敛速度/计算复杂度。为了公平对比，我们计算所有算法在对应数据集上能达到的最高验证准确率$Acc_{max}$，并记录各自它们达到$0.90\times Acc_{max}$所需要的时间，此时算法接近收敛。该指标基本上内存指标呈正相关，因为对历史信息的存储本身就是时间消耗行为。相关对比结果如下表所示：
	  ![[Pasted image 20250530111357.png]]
	  实验结果表明，我们的算法在学习和训练效率上要优于MAML、ANIL和ITD-BiO此类基于迭代微分的元学习算法。
4. 成果公开
   * 相关论文成果已经整理成论文“Memory-Reduced Meta-Learning with Guaranteed Convergence”并发表在国际顶级人工智能会议(CCF-A类)AAAI-2025。
   * 相关研究成果正在整理为发明专利。
## 存在的不足及今后努力的方向
### 存在的不足
我们设计的基于优化的元学习算法在内存消耗占用和收敛性方面取得一些进展，并在计算机视觉图像分类领域benchmarks上取得较好成果，但是在理论完备性和实际应用推广中仍然存在一些不足之处。
1. 应用领域迁移的挑战
   论文中的实验评估基于计算机视觉领域的图像分类任务，将其直接应用到网络流量分类检测中，其有效性和性能表现有待验证，这期间存在一些差异。
   * 数据结构化差异和表征
     网络流量数据包括数据头部、数据载荷、流统计信息和日志条目等，与图像数据结构在数据分布、结构、语义等存在较大差别，需要对流量数据进行清洗，特征工程等预处理操作，将网络流量转化为适合算法框架的输入表征。
   * 数据集构建
     小样本图像领域数据集数量和质量都高于网络流量数据集，在不同场景下需要定义元学习 中的“任务”单元，构建高质量的support set和query set。
   * 模型架构适应与调整
     论文中实验使用模型的是适用于计算机视觉领域的CNN架构，被设计于处理图像等数据，在迁移到网络流量数据场景下，除了对数据进行预处理，往往还需要选取或者结合其他的网络架构如RNN，LSTM和Transform等。
2. 理论假设的局限性
   在之前的研究工作中，我们对算法的理论分析建立在一系列标准假设上，例如下层函数的强凸性，梯度函数估计的无偏性和有界方差。然而实际中的流量往往高度复杂且充满噪声，这可能会对算法在实际应用的稳定性带来较大影响。
3. 超参数调优
   元学习算法由于其上下层的耦合性，学习性能往往对超参数比较敏感，在复杂流量应用场景下，找到适合的超参数往往需要大量工程实践调优。
### 今后努力的方向
前期在校期间的工作主要是结合人工智能和优化算法，尝试运用在网络流量检测场景下。未来在企期间，计划着眼于更加广阔的人工智能和安全交叉领域，聚焦于“AI for Security”和“Security of AI”两大核心方向，集合具体的企业实际工程项目，探索前沿技术的工程落地实践，例如安全垂直领域的**安全大模型**和致力于构建可信AI的**大模型安全**。

# key-words
## 攻击
**“0-day”指的是软件供应商还未知晓，或者知晓但还未来得及发布补丁的安全漏洞**。利用0-day漏洞发起的攻击，让系统在毫无防备的情况下遭受威胁。例如，黑客发现了某常用软件的一个未公开漏洞，迅速编写恶意代码进行攻击，软件用户就可能面临数据泄露等风险。

“APT攻击”即**高级持续性威胁攻击**，是一种有组织、长期且针对性强的网络攻击。攻击者通常以特定目标为对象，如政府机构、企业等，通过长期潜伏、逐步渗透，获取敏感信息。像某黑客组织长期针对一家金融机构，先通过钓鱼邮件植入恶意程序，然后在该机构网络中潜伏数月，不断收集数据，最后实现窃取关键金融数据的目的。

0-day和APT攻击都具有很强的隐蔽性和危害性，**0-day侧重于利用未被修复的漏洞**，而APT攻击强调**攻击的长期持续性和针对性**。 

U2R（User to Root）类型攻击指的是**攻击者先以普通用户身份进入系统，然后利用系统漏洞等手段，将权限提升到超级用户（root）权限**，从而获取系统的完全控制权。比如攻击者通过发现某个服务程序的漏洞，在普通用户权限下执行特定代码，绕过系统安全机制，实现权限提升。

R2L（Remote to Local）类型攻击是**指攻击者从远程网络对本地系统发起攻击，目标是在本地系统获取普通用户权限**。例如，攻击者利用远程服务器的某个网络服务端口漏洞，通过发送特制的网络数据包，在本地系统上执行恶意代码，进而获得本地系统的用户账号和密码等信息，达到获取普通用户权限的目的。 
## 经验风险最小化问题
通过最小化经验风险来寻找最优模型的相关问题。经验风险是**基于训练数据上的损失函数的平均**，反映了模型在**已知训练样本上**的预测误差。解决该问题，就是要找到一种算法或策略，使得模型在训练数据上的经验风险达到最小，从而**期望模型在新数据上也能有较好的泛化性能**。

## 梯度消失和梯度爆炸
梯度消失指在神经网络反向传播计算梯度时，梯度值随着网络层数加深不断减小，趋近于0，导致靠近输入层的神经元参数更新缓慢甚至几乎不更新，使得模型难以学习到有效的特征，训练效果不佳。比如在一个非常深的神经网络中训练图像识别模型，底层神经元参数几乎不改变，无法有效提取图像底层特征。
梯度爆炸则是在反向传播时，梯度值随着网络层数加深不断增大，导致参数更新幅度过大，模型变得不稳定，无法收敛。例如在训练语言模型时，梯度爆炸可能使模型的参数更新失控，出现结果完全偏离预期的情况。 
## $\mu-$强凸函数
“$\mu-$强凸函数”是凸函数概念的一种强化。在数学分析与优化理论中，对于定义在凸集上的实值函数$f$，若它满足对于任意的$x,y$属于该凸集以及任意$\alpha\in[0,1]$，有$f(\alpha x+(1-\alpha)y)\leq\alpha f(x)+(1-\alpha)f(y)$，则称$f$是凸函数。
而$\mu-$强凸函数在此基础上进一步要求存在一个常数$\mu > 0$，使得对于任意的$x,y$属于该凸集，都有$f(y)\geq f(x)+\nabla f(x)^T(y - x)+\frac{\mu}{2}\|y - x\|^2$成立。
这里$\nabla f(x)$是函数$f$在$x$处的梯度，$\|y - x\|$表示$y$与$x$之间的某种范数（比如欧几里得范数）。
**常数$\mu$刻画了函数的“强凸程度”，$\mu$越大，函数的下凸性就越强，其图像弯曲得越厉害。$\mu-$强凸函数在优化算法收敛性分析等方面有重要应用**，比如在梯度下降算法中，对于$\mu-$强凸函数能保证更快的收敛速度。 

## 函数的条件数
在优化领域，比值$\kappa=\frac{l_g}{\mu}$被称为函数 g 的**条件数 (condition number)**。
它是一个非常重要的指标，用来衡量与函数 g 相关的优化问题的“病态”程度或求解难度。
下面是关于它含义的几点具体解释：
1. **衡量曲率的比率**：
    - μ-强凸性 (μ-strong convexity) 保证了函数 g 的曲率有一个**下界**。你可以把它想象成，函数图像最平坦的地方“弯曲”程度也至少是 μ。
    - ∇g 的 $l_g$​-Lipschitz 连续性（也称为 lg​-平滑性）为函数 g 的曲率提供了一个**上界**。这可以想象成，函数图像最陡峭的地方“弯曲”程度也不会超过 lg​。
    - 因此，条件数 κ=μlg​​ 代表了函数最大曲率和最小曲率之间的比率。
2. **对优化算法的影响**：
    - 条件数 κ 直接**影响梯度下降等一阶优化算法的收敛速度。**
    - **对于一个病态问题（κ 很大），优化算法会**面临挑战。在曲率大的方向（椭圆的短轴方向），梯度会很大，容易导致步长太大而产生震荡；在曲率小的方向（椭圆的长轴方向），梯度会很小，导致收敛极其缓慢。
    - 对于梯度下降法，其收敛率通常与 κ 相关，例如，收敛速度的一个上界因子是 (1−κ1​) 或 (κ+1κ−1​)2。当 κ 很大时，这个因子会非常接近 1，意味着每次迭代的目标函数值下降得非常少，收敛需要很多步。
    - 相反，当 κ 很小时，收敛速度会非常快。
**总结**
简单来说，**条件数 κ 是一个衡量优化问题难度的数值**。一个高的条件数意味着函数的几何形状不规则（像一个狭长的山谷），这会严重拖慢标准优化算法的收敛速度。
## $\epsilon$-解
在优化和数值分析中，**$\epsilon$-解**（$\epsilon$-solution）是一个用来描述问题的近似解的概念。它表示一个在指定容差范围内“足够接近”真实解的解。这个容差范围由一个正数$\epsilon$表示。
首先，公式如下：

$$
\frac{1}{T}\sum_{t=0}^{T-1}{\mathbb{E} \left[ \parallel \nabla F\left( \theta _t \right) \parallel ^2 \right]}\le \epsilon
$$

### 公式中的符号解释：
1. **$T$**：表示算法运行的总迭代次数。
2. **$\theta_t$**：表示算法在第$t$次迭代时的参数值。
3. **$F(\theta_t)$**：表示目标函数（通常是损失函数）在参数$\theta_t$处的值。
4. **$\nabla F(\theta_t)$**：表示目标函数$F$在参数$\theta_t$处的梯度（导数）。
5. **$\parallel \nabla F(\theta_t) \parallel^2$**：表示梯度的平方范数，衡量梯度的大小。
6. **$\mathbb{E}[\cdot]$**：表示期望值，通常用于处理随机性（例如随机梯度下降中的随机性）。
7. **$\epsilon$**：表示一个小的正数，用来衡量算法的收敛精度。
### 公式的含义：
公式的左侧是一个平均值：

$$
\frac{1}{T}\sum_{t=0}^{T-1}{\mathbb{E} \left[ \parallel \nabla F\left( \theta _t \right) \parallel ^2 \right]}
$$
它表示在$T$次迭代中，目标函数梯度平方范数的期望值的平均值。梯度的平方范数通常用于衡量优化过程中的收敛情况。**如果梯度的平方范数很小，说明算法已经接近目标函数的极小值点（即梯度接近零）。**
在$T$次迭代后，目标函数梯度平方范数的平均值不会超过$\epsilon$。
### 直观解释：
这个公式是优化算法收敛性的一个数学表达。它说明：
- 在足够多的迭代次数$T$后，算法能够使目标函数的梯度平方范数的平均值变得很小（小于或等于$\epsilon$）。
- 这意味着算法逐渐接近目标函数的极小值点（梯度接近零），从而达到优化的目的。
### 应用场景：
这种收敛性条件通常用于分析优化算法（例如随机梯度下降、Adam等）的性能，确保算法能够在有限的迭代次数内达到一定的精度。
## 迭代微分与反向传播
$$\begin{matrix}
	&		\frac{\partial f_{\mathcal{B}}(\theta ,\boldsymbol{\phi }^K(\theta ))}{\partial \theta}=\frac{1}{|\mathcal{B} |}\sum_{i=1}^{|\mathcal{B} |}{\frac{\partial f_i(\theta ,\phi _{i}^{K}(\theta ))}{\partial \theta}}\\
	&		=\frac{1}{|\mathcal{B} |}\sum_{i=1}^{|\mathcal{B} |}{\left( \nabla _{\theta}f_i(\theta ,\phi _{i}^{K}(\theta ))-\lambda _{\phi}\sum_{k=0}^{K-1}{\nabla _{\theta \phi}^{2}g_i(\theta ,\phi _{i}^{k}(\theta ))}\times \right.}\\
	&		\left. \quad \prod_{q=k+1}^{K-1}{\left( I\!-\!\lambda _{\phi}\nabla _{\phi}^{2}g_i(\theta ,\phi _{i}^{q}(\theta )) \right) \nabla _{\phi}f_i(\theta ,\phi _{i}^{K}(\theta ))} \right) .\\
\end{matrix}$$
$$\frac{\partial f_i\left( \theta ,\phi _{i}^{K}(\theta ) \right)}{\partial \theta}=\nabla _{\theta}f_i\left( \theta ,\phi _{i}^{K}(\theta ) \right) +\frac{\partial \phi _{i}^{K}(\theta )}{\partial \theta}\nabla _{\phi}f_i\left( \theta ,\phi _{i}^{K} \right) 
$$
$$
\phi _{i}^{k}\left( \theta \right) =\phi _{i}^{k-1}\left( \theta \right) -\lambda _{\phi}\nabla _{\phi}g_i\left( \theta ,\phi _{i}^{k-1}\left( \theta \right) \right) \,\,for\,\,k=1,...K
$$
两边同时对$\theta$求导，
$$
\begin{aligned}
	\frac{\partial \phi _{i}^{k}\left( \theta \right)}{\partial \theta}=&\frac{\partial \phi _{i}^{k-1}\left( \theta \right)}{\partial \theta}-\lambda _{\phi}\nabla _{\theta \phi}g_i\left( \theta ,\phi _{i}^{k-1}\left( \theta \right) \right) -\lambda _{\phi}\frac{\partial \phi _{i}^{k-1}\left( \theta \right)}{\partial \theta}\nabla _{\phi}^{2}g_i\left( \theta ,\phi _{i}^{k-1}\left( \theta \right) \right)\\
	=&\frac{\partial \phi _{i}^{k-1}\left( \theta \right)}{\partial \theta}(I-\lambda _{\phi}\nabla _{y}^{2}g_i(\theta ,\phi _{i}^{k-1}(\theta )))-\lambda _{\phi}\nabla _{\theta \phi}g_i(\theta ,\phi _{i}^{k-1}(\theta ))\\
\end{aligned}
$$
两边从k=1到k=K累乘：
$$
\begin{aligned}
	\frac{\partial \phi _{i}^{K}\left( \theta \right)}{\partial \theta}&=\frac{\partial \phi _{i}^{0}\left( \theta \right)}{\partial \theta}\prod_{k=0}^{K-1}{(I-\lambda _{\phi}\nabla _{y}^{2}g_i(\theta ,\phi _{i}^{k}(\theta )))}-\lambda _{\phi}\sum_{k=0}^{K-1}{\nabla _{\theta \phi}^{2}g_i\left( \theta ,\phi _{i}^{k}\left( \theta \right) \right) \prod_{q=k+1}^{K-1}{\left( I-\lambda _{\phi}\nabla _{\phi}^{2}g_i\left( \theta ,\phi _{i}^{q}\left( \theta \right) \right) \right)}}\\
	&=-\lambda _{\phi}\sum_{k=0}^{K-1}{\nabla _{\theta \phi}^{2}g_i\left( \theta ,\phi _{i}^{k}\left( \theta \right) \right) \prod_{q=k+1}^{K-1}{\left( I-\lambda _{\phi}\nabla _{\phi}^{2}g_i\left( \theta ,\phi _{i}^{q}\left( \theta \right) \right) \right)}}\\
\end{aligned}
$$
## 超梯度估计公式
在解决上面的双层优化问题中，在给定点$\theta$,计算f的梯度，需要知道$\phi^{*}(\theta)$, 然而，除非内部问题有一个封闭形式的解，否则$\phi^*(\theta)$是无法得到的。因此，我们假设对于任意$\theta \in X$，我们有$\phi^*(\theta)$的一个近似值，该近似值用于估计超梯度。
根据隐函数定义：
![[Pasted image 20250606011304.png]]
![[Pasted image 20250606011436.png]]
![[Pasted image 20250606011425.png]]

## 二次规划问题和共轭梯度
### 二次规划问题
![[Pasted image 20250606011651.png]]
这句话的意思是：**求解这个线性系统等价于求解一个二次规划问题**。具体来说，这个二次规划问题的目标是最小化以下目标函数：

$$
\min_v \quad \frac{1}{2} v^T \nabla^2_y g(x_k, y^D_k) v - v^T \nabla_y f(x_k, y^D_k).
$$

目标函数对$v$求导，最优解对应的条件即为线性系统方程。
### 共轭梯度法（Conjugate Gradient Method）

这个算法是一个子程序，用于在第 $t$ 次外层循环中估计 Hessian 矩阵的逆与向量的乘积（Hessian-inverse-vector product）。以下是对算法的逐步解释：
#### 初始化
1. 如果 $t > 0$，则将上一轮迭代的结果 $v_{i,t-1}^{N}$ 作为当前迭代的初始值 $v_{i,t}^{0}$。
2. 如果 $t = 0$，则初始化 $v_{i,t}^{0} = \bm{0}_{q}$，即一个全零向量。
3. 初始化残差 $r_{i,t}^0$ 和搜索方向 $p_{i,t}^0$：
   $$
   r_{i,t}^0 = p_{i,t}^0 = \nabla_{\phi}f_i(\theta_t,\phi_{i,t}^{K}) - \nabla_{\phi}^2g_i(\theta_t, \phi_{i,t}^{K})v_{i,t}^0.
   $$
#### 迭代过程
算法通过共轭梯度法（Conjugate Gradient Method）进行 $N$ 次迭代，逐步逼近 Hessian 矩阵的逆向量乘积。
4. **循环开始**：对 $n = 0, 1, ..., N-1$ 进行迭代：
   - 计算 Hessian 矩阵与搜索方向 $p_{i,t}^n$ 的乘积：
     $$
     h_{i,t}^{n} = \nabla_{\phi}^{2}g_{i}(\theta_{t},\phi_{i,t}^{K})p_{i,t}^{n}.
     $$
   - 计算步长 $\eta_{i,t}^{n}$：
     $$
     \eta_{i,t}^{n} = \frac{{r_{i,t}^{n}}^{T}r_{i,t}^{n}}{{p_{i,t}^{n}}^{T}h_{i,t}^{n}}.
     $$
   - 更新估计值 $v_{i,t}^{n+1}$：
     $$
     v_{i,t}^{n+1} = v_{i,t}^{n} + \eta_{i,t}^{n}p_{i,t}^{n}.
     $$
   - 更新残差 $r_{i,t}^{n+1}$：
     $$
     r_{i,t}^{n+1} = r_{i,t}^{n} - \eta_{i,t}^{n}h_{i,t}^{n}.
     $$
   - 计算 $\zeta_{i,t}^{n}$，用于调整搜索方向：
     $$
     \zeta_{i,t}^{n} = \frac{{(r_{i,t}^{n+1})}^{T}r_{i,t}^{n+1}}{{r_{i,t}^{n}}^{T}r_{i,t}^{n}}.
     $$
   - 更新搜索方向 $p_{i,t}^{n+1}$：
     $$
     p_{i,t}^{n+1} = r_{i,t}^{n+1} + \zeta_{i,t}^{n}p_{i,t}^{n}.
     $$
4. **循环结束**：完成 $N$ 次迭代后，输出 $v_{i,t}^{N}$。
#### 输出
- 输出 $v_{i,t}^{N}$，即经过 $N$ 次迭代后估计的 Hessian-inverse-vector product。
#### 算法核心思想
这个子程序的核心是利用共轭梯度法来高效地逼近 Hessian 矩阵的逆与向量的乘积，而不需要显式地计算 Hessian 矩阵的逆。通过迭代更新，可以逐步优化结果，达到较高的精度。
### 线性加速（Linear Acceleration）
共轭梯度法（Conjugate Gradient Method）是一种迭代算法，用于求解线性方程组，特别是涉及对称正定矩阵的情况。它的线性加速能力体现在每次迭代中能够快速减少误差，使其在处理大规模问题时非常高效。
#### 核心思想：
共轭梯度法通过沿着共轭方向（Conjugate Directions）逐步改进解来最小化与方程组相关的二次型。这些共轭方向的选择确保在一个方向上的最小化不会抵消之前方向上的进展。
#### 误差减少：
共轭梯度法中的误差减少速度由系数矩阵 $A$ 的特征值决定。设线性方程组为：
$$
Ax = b,
$$
其中：
- $A$ 是对称正定矩阵，
- $x$ 是待求解的解向量，
- $b$ 是右端项向量。
在第 $k$ 次迭代时的误差 $e_k = x_k - x^*$（其中 $x^*$ 是真实解）满足以下关系：
$$
\|e_k\|_A \leq \|e_0\|_A \cdot \left(\frac{\sqrt{\kappa} - 1}{\sqrt{\kappa} + 1}\right)^k,
$$
其中：
- $\|e_k\|_A = \sqrt{e_k^T A e_k}$ 是误差的 $A$-范数，
- $\kappa = \frac{\lambda_{\text{max}}}{\lambda_{\text{min}}}$ 是矩阵 $A$ 的条件数，$\lambda_{\text{max}}$ 和 $\lambda_{\text{min}}$ 分别是 $A$ 的最大和最小特征值。
#### 解释：
公式中的项 $\left(\frac{\sqrt{\kappa} - 1}{\sqrt{\kappa} + 1}\right)^k$ 表明误差随着迭代次数 $k$ 的增加呈指数级下降。这种快速的误差减少体现了共轭梯度法的线性加速能力，尤其是在条件数 $\kappa$ 不太大的情况下。
#### 总结：
共轭梯度法通过利用问题的结构特性（例如矩阵 $A$ 的对称性和正定性），并沿着共轭方向迭代最小化二次型，从而实现快速的误差减少。这使得它成为解决大规模线性方程组的高效工具，**特别适合大型稀疏矩阵**

## 热启动
“热启动”指在优化算法中，**利用上一次相似问题的解或相关信息，作为本次求解的初始值，这样可以加快算法的收敛速度**，减少计算量。比如在多次求解类似结构的线性方程组时，前一次的解可作为下一次求解的起点。
## 函数性质
### Lipschitz 连续性
Lipschitz 连续性是一个函数的平滑性条件。一个函数 $f(x)$ 被称为是 **Lipschitz 连续** 的，如果存在一个常数 $L \geq 0$，使得对于任意的 $x, y$ 都满足：

$$
\|f(x) - f(y)\| \leq L \|x - y\|.
$$

这里的 $L$ 被称为 **Lipschitz 常数**。直观上，这意味着函数的变化率不会超过某个固定的上界 $L$，即**函数不会“变化得太快”**。

在优化问题中，常见的一个特殊情况是函数的梯度 $\nabla f(x)$ 是 Lipschitz 连续的，即：

$$
\|\nabla f(x) - \nabla f(y)\| \leq L \|x - y\|.
$$

这表明梯度的变化也是受限的，**函数的曲率不会过于剧烈**。
### 梯度的无偏性
梯度的无偏性通常出现在随机优化算法（如随机梯度下降，SGD）中。在这些算法中，我们通常使用一个随机梯度估计 $\hat{\nabla} f(x)$ 来近似真实的梯度 $\nabla f(x)$。

**梯度的无偏性意味着随机梯度的期望值等于真实梯度**，即：

$$
\mathbb{E}[\hat{\nabla} f(x)] = \nabla f(x).
$$

这里的 $\mathbb{E}$ 表示期望值。无偏性**保证了随机梯度在长期平均意义上是准确的**，不会系统性地偏离真实梯度。
### 有界方差
有界方差是对随机梯度估计的波动性（噪声）的限制条件。具体来说，假设随机梯度 $\hat{\nabla} f(x)$ 的方差是有限的，即存在一个常数 $\sigma^2 \geq 0$，使得：

$$
\mathbb{E}[\|\hat{\nabla} f(x) - \nabla f(x)\|^2] \leq \sigma^2.
$$

这里的 $\sigma^2$ 是方差的上界，**表示随机梯度的波动不会超过某个固定值**。这一性质在分析随机优化算法的收敛性时非常重要，因为**它限制了随机梯度的噪声水平**。
### 总结
- **Lipschitz 连续性**：函数或梯度的变化率有上界。
- **梯度的无偏性**：随机梯度的期望等于真实梯度。
- **有界方差**：随机梯度的波动（方差）有上界。
## 收敛性
### 线性收敛速率
如果一个迭代算法的误差序列 $\{e_k\}$ 满足以下关系：
$$
e_{k+1} \leq C \cdot e_k,
$$
其中 $C \in (0, 1)$ 是一个常数，那么我们称该算法具有**线性收敛速率**。线性收敛意味着**误差以固定比例逐步减小**。
### 次线性收敛速率
**次线性收敛速率则表示误差的减小速度比线性收敛慢**。具体来说，如果误差序列 $\{e_k\}$ 满足：
$$
\lim_{k \to \infty} \frac{e_{k+1}}{e_k} = 1,
$$
那么我们称该算法具有次线性收敛速率。这意味着随着迭代次数增加，误差的减小比例趋近于 1，而不是一个固定的常数 $C < 1$。
### 举例
一个典型的次线性收敛速率的例子是误差序列满足：
$$
e_k = \frac{1}{k}.
$$
在这种情况下，**误差随着迭代次数 $k$ 增加而减小，但减小的速度逐渐变慢**。
### 总结
次线性收敛速率通常出现在某些优化算法中，尤其是当问题的条件较差或算法本身的性质限制了收敛速度时。与线性收敛相比，次线性收敛速度较慢，但仍然能够保证算法最终收敛到一个解。

公式如下：

$$
\frac{1}{T+1}\sum_{t=0}^T{\mathbb{E} \left[\left\| \nabla F_{\mathcal{B}}(\theta _t) \right\| ^2\right]}\le \mathcal{O} \left( \frac{1}{T} \right) +\mathcal{O} \left( \frac{1}{|\mathcal{B}|} \right).
$$

### 公式中的符号解释

1. **$\theta_t$**：表示优化算法在第 $t$ 次迭代时的模型参数。
2. **$F_{\mathcal{B}}(\theta_t)$**：表示基于一个小批量数据 $\mathcal{B}$ 的目标函数（通常是损失函数）。
3. **$\nabla F_{\mathcal{B}}(\theta_t)$**：表示目标函数 $F_{\mathcal{B}}$ 关于参数 $\theta_t$ 的梯度。
4. **$\|\nabla F_{\mathcal{B}}(\theta_t)\|^2$**：表示梯度的平方范数，衡量当前梯度的大小。
5. **$\mathbb{E}[\cdot]$**：表示期望值，通常是对随机性（如小批量数据 $\mathcal{B}$ 的采样）取平均。
6. **$T$**：表示总的迭代次数。
7. **$|\mathcal{B}|$**：表示小批量数据 $\mathcal{B}$ 的大小（即 batch size）。
8. **$\mathcal{O}(\cdot)$**：表示渐近复杂度，用来描述某个量随着变量变化的增长速度。

### 公式的含义

公式左边：

$$
\frac{1}{T+1}\sum_{t=0}^T{\mathbb{E} \left[\left\| \nabla F_{\mathcal{B}}(\theta _t) \right\| ^2\right]}
$$

表示在 $T+1$ 次迭代中，梯度平方范数的期望值的平均值。这个值可以用来衡量优化算法的收敛性。**如果这个值很小，说明梯度接近于零，优化算法已经接近收敛**。
公式右边：

$$
\mathcal{O} \left( \frac{1}{T} \right) +\mathcal{O} \left( \frac{1}{|\mathcal{B}|} \right)
$$

表示梯度平方范数的上界由两部分组成：
1. $\mathcal{O} \left( \frac{1}{T} \right)$：随着迭代次数 $T$ 的增加，这部分会逐渐减小，表示算法的收敛速度。
2. $\mathcal{O} \left( \frac{1}{|\mathcal{B}|} \right)$：随着小批量大小 $|\mathcal{B}|$ 的增加，这部分也会减小，表示小批量数据的随机性对优化的影响。
### 公式的意义
这条公式表明，优化算法的收敛性受到两方面的影响：
1. **迭代次数 $T$**：更多的迭代次数可以让算法更接近收敛。
2. **小批量大小 $|\mathcal{B}|$**：更大的小批量可以减少梯度估计的随机性，从而提高收敛速度。
最终，梯度平方范数的期望值的平均值会随着 $T$ 和 $|\mathcal{B}|$ 的增加而减小，达到更好的优化效果。
## 条件数
$g(\theta ,\phi )\triangleq \mathbb{E} _{\mathcal{T} _i\sim \mathcal{P} (\mathcal{T} )}[g_i(\theta ,\phi )]$
为$\mu-$强凸函数，$\nabla g$是$l_g-$Lipschitz连续的，
函数的条件数为$\kappa=\frac{l_g}{\mu}$.
### 1. 强凸性（\(\mu\)-强凸性）
#### 解释：
- **强凸性**保证了函数 \( g(\theta, \phi) \) 具有唯一的最小值（即唯一的最优解）。
- 它还表明，函数值 \( g(\theta, \phi) \) 在远离最小值时至少以二次函数的速度增长。
### 2. 梯度的Lipschitz连续性（\(l_g\)-Lipschitz连续性）
#### 解释：
- **Lipschitz连续性**表明梯度的变化不会过于剧烈。
- 这一性质对于优化算法的稳定性非常重要，因为它限制了梯度的变化范围，避免优化过程中的数值不稳定。
### 3. 条件数（\(\kappa\)）

函数 \( g(\theta, \phi) \) 的 **条件数** 定义为梯度的Lipschitz常数 \(l_g\) 与强凸性常数 \(\mu\) 的比值：
$$
\kappa = \frac{l_g}{\mu}.
$$
#### 解释：
- 条件数 \(\kappa\) 衡量了函数在优化过程中的“良好条件性”。
- **较小的 \(\kappa\) 表示函数的优化难度较低，优化算法收敛速度较快**。
- 较大的 \(\kappa\) 表示函数的优化难度较高，可能存在不同方向上的曲率差异较大，从而导致优化过程较慢。
### 总结
1. **\(\mu\)-强凸性**：保证函数 \( g(\theta, \phi) \) 有唯一的最优解，并且函数值远离最优解时至少以二次函数的速度增长。
2. **\(l_g\)-Lipschitz连续性**：限制了梯度的变化幅度，确保梯度变化平滑，从而优化过程更加稳定。
3. **条件数 \(\kappa = \frac{l_g}{\mu}\)**：衡量函数优化的难易程度。较小的条件数意味着优化更容易，较大的条件数则表示优化可能更困难。

## 1D-CNN
“一维CNN”指一维卷积神经网络（Convolutional Neural Network）。它是CNN的一种类型，其卷积核在一维数据上滑动执行卷积操作。与处理二维图像数据的二维CNN不同，**一维CNN主要用于处理序列数据，如时间序列数据（像股票价格随时间的变化序列）、文本数据（文本可看作字符或词的序列）**。 
