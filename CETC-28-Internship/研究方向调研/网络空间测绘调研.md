# 理论基础
## 什么是网络空间测绘
网络空间测绘是一种通过综合运用**多种主动与被动探测及分析技术**,对网络  空间中的各类资产进行全面、深入探测和精准分析,并以**可视化**的方式呈现其**内在结构和相互关系**的技术手段。它类似于现实世界中的地理测绘,旨在绘制一张详细的网络空间地图,实现**网络资产与行为的可视化、威胁感知与攻防支撑**。
## 为什么需要网络空间测绘
网络空间测绘的结果既能反映网络当前的安全态势，也可揭示网络行为规律。业内常用的比喻是，“网络空间测绘技术旨在**构建一张网络空间信息的‘作战地图’**”，可直观反映网络资源属性和发展趋势。在攻防对抗中起到强力支撑的作用：
1. ==现代安全防御的基础==
   知己知彼知威胁，**攻击面管理(ASM)** 作为一种全面性的安全策略,旨在识别、评估和降低组织的攻击面。它不仅关注传统的网络边界,还涵盖了所有可能成为攻击入口的资产和漏洞，例如云环境以及各种物联网设备。在攻击面管理中，网络资产测绘可以：
	- **全面发现资产**，攻击者的行动通常始于对目标资产情报的收集 ；因此，防御者必须以同样的视角，甚至更全面的广度和更快的频率来审视自身的资产暴露情况，从而前置性地发现并修复风险
	- **实时动态监测**，测绘结果随网络变化而动态变化
	- **资产的属性识别**，除了发现资产以及其IP、开放端口外，更关键的是要确定在该端口上运行的服务、应用、操作系统、硬件设备、代码依赖、甚至是社会关联等多种属性。这个过程就是**资产的属性识别**
2. ==基于测绘的防御策略优化==
   通过网络空间测绘识别出暴露资产后,组织可以利用这些数据来优化自身的防御策略,从而在攻防对抗中占据更有利的位置：
	- **风险评估与排序**，根据测绘结果中的资产属性和资产的重要性，对暴露资产进行风险评估和排序，从而合理编排安全资源。
	- **漏洞修复**，测绘的数据分析过程中往往结合威胁情报进行，安全团队可以及时发现存在的漏洞,并制定相应的漏洞修复和补丁管理计划，同时,根据资产的业务需求和风险级别，合理安排修复时间,避免因修复操作对正常业务造成影响。
	- **访问控制策略调整**，基于测绘发现的暴露资产和资产的访问权限情况，基于最小权限原则优化访问控制策略
	- **应急预案完善**，了解到哪些资产可能成为攻击的重点目标以及资产之间的关联关系后，安全团队可以预测攻击路径，针对性制定可操作的应急处置方案。
3. ==快速响应、修复、溯源==，发生安全事件后，一份详尽的资产清单是应急响应团队的“作战地图”：
    - **快速响应修复**，通过测绘结果中的资产属性和关联关系，快速评估攻击的影响范围（同一网段主机或存在业务关联系统等）、识别横向移动的路径、进行数字取证，并有效隔离受影响的系统 。
    - **溯源分析**，动态的资产测绘数据还能用于丰富攻击者画像，通过分析攻击者使用的基础设施（如C2服务器、钓鱼网站）的指纹特征，可以反向利用测绘技术发现其更多的攻击资源，为威胁预警和溯源提供支持。
# 网络空间测绘技术体系
## 核心技术
> 网络空间测绘技术体系主要包括三个大的方面,即**网络资产探测技术、数据分析技术和可视化技术**
![网络空间测绘技术体系.png](https://images.mauga.top/2025/10/42f951ebea25f638b28be063b939be6b.png)

### 网络资产探测
> 网络资产探测的技术核心，聚焦于两大支柱性问题：如何通过网络探测来发现潜在的资产（数据采集），以及如何精确地识别这些资产的真实身份（指纹识别）
#### 资产发现
> 网络资产是任何通过网络进行通信并拥有数字足迹的实体，不仅包括所有构成网络基础设施的**物理实体**，如服务器、路由器、交换机、防火墙、工作站、打印机，以及近年来爆炸式增长的物联网（IoT）设备；还包括无形的、软件定义或配置生成的**逻辑实体**，例如运行的服务（如Web服务、数据库服务）、部署的应用程序、虚拟机、容器、域名、TLS/SSL证书、以及IP地址段本身。
##### 主动探测
###### 主机存活发现
> 探测的第一步，旨在确定一个IP地址是否关联着一个在线的、活跃的主机

常用的技术包括：
1. **ICMP探测**。最典型的是`ping`命令，它发送`ICMP Echo Request`报文，并等待`Echo Reply`。然而，许多网络设备和防火墙会出于安全考虑而阻止ICMP流量，导致这种方法并不可靠。其他ICMP类型，如时间戳请求（Timestamp Request）和地址掩码请求（Address Mask Request），有时也能绕过简单的`ping`过滤
2. **TCP/IP探测**。向目标的常用端口（如TCP 80端口或UDP 53端口）发送探测包。如果收到`TCP SYN/ACK`或有效的UDP响应，则表明主机存活。这种方法更为可靠
3. **ARP扫描**。在局域网（LAN）环境中，ARP扫描是最高效和准确的主机发现方法。它通过发送ARP请求来解析IP地址对应的MAC地址，由于ARP是二层协议，通常不会被防火墙或上层安全策略所限制
###### 端口扫描
> 在确认主机存活后，端口扫描旨在发现该主机上开放了哪些TCP或UDP端口，这些端口是其对外提供服务的窗口。

1. **TCP-SYN扫描**：也称为“半开放”扫描。扫描器发送一个TCP SYN包，如果收到SYN/ACK响应，则端口开放；如果收到RST，则端口关闭。扫描器随后发送RST包中断连接，而不是完成标准的三次握手。这种方式速度快，且不易被简单的日志系统记录，是目前最流行和高效的扫描方式 
2. **TCP Connect扫描 (`-sT`)**：扫描器使用操作系统的标准`connect()`系统调用，与目标端口完成完整的三次握手。这种方式虽然可靠，但速度较慢，且极易被目标主机记录下来，隐蔽性差
3. **UDP扫描 (`-sU`)**：UDP是无连接协议，因此扫描难度更大。扫描器发送一个UDP包到目标端口。如果收到==ICMP“端口不可达”错误==，则端口关闭。如果没有任何响应，则端口可能开放或被过滤。如果收到UDP响应，则端口确定开放。这种扫描方式速度慢且结果不确定性高
4. 其他扫描技术，如FIN、NULL、Xmas扫描，通过发送非标准的TCP标志位组合来探测，旨在绕过某些无状态防火墙（这类防火墙不记录连接的 “上下文”（比如是否刚允许过某个 IP 的 SYN 请求），只靠 “匹配预设规则” 拦截 —— 最常见的规则是 “拦截没有 ACK 的 SYN 报文”（防止外部主动发起连接扫描）的检测

**主流网络扫描器对比分析**：

| 特性   | **Nmap**          | **ZMap**                    | **Masscan**         |
| ---- | ----------------- | --------------------------- | ------------------- |
| 核心架构 | 有状态，基于内核协议栈       | 无状态，异步，用户态协议栈               | 无状态，异步，独立的TCP/IP协议栈 |
| 主要用途 | 局域网/特定目标的深度、精细化扫描 | 互联网范围的广度、高速单端口普查            | 互联网范围的广度、超高速多端口普查   |
| 扫描速度 | 较慢，取决于并发度和目标响应    | 极快，可达千兆线速（约1.4M pps）        | 极快，宣称可达10M pps      |
| 状态管理 | 在内存中为每个连接维护状态     | 无状态，将验证信息编码在出站包中            | 无状态，设计理念与ZMap类似     |
| 灵活性  | 极高，支持多种扫描类型和NSE脚本 | 较低，专注于发送单包探测                | 较高，支持任意地址和端口范围      |
| 资源消耗 | 内存消耗随并发数增加        | 内存消耗极低，固定                   | 内存消耗极低，固定           |
| 适用场景 | 渗透测试、详细资产清点、漏洞评估  | 学术研究、全网协议部署率统计、快速发现特定漏洞的暴露面 | 快速构建全网资产数据库、大规模威胁狩猎 |
##### 被动侦察
> 被动侦察是指在不直接与目标系统交互的情况下收集信息。这种方法虽然隐蔽性极强，但获得的信息可能不完整或已过时。

常见手段包括：
1. **分析公开数据源**：查询WHOIS数据库获取域名注册信息，分析DNS记录（A[域名->IP]、MX[指定负责接收某域名邮件的邮件服务器地址]、NS[指定管理某域名 DNS 解析的权威 DNS 服务器地址]、TXT等）来映射组织的网络结构
2. **监控网络流量**：利用网络望远镜（Network Telescope）或暗网（Darknet）——即一段已宣告但未使用的IP地址空间——来被动地接收和分析背景辐射流量（如扫描流量、蠕虫传播、DDoS反射攻击的响应包等）。通过分析这些流量的来源和目标，可以洞察全球范围内的扫描活动和恶意行为趋势
3. **利用第三方数据**：直接使用或购买来自网络空间搜索引擎、证书透明度日志、泄露数据等第三方提供的数据
#### 指纹识别
> 发现一个开放的端口仅仅是第一步，更关键的是要确定在该端口上运行的是什么服务、什么应用、什么操作系统，乃至什么型号的硬件设备。这个过程就是**资产指纹识别（Asset Fingerprinting）**，其中指纹是指一个网络服务、操作系统或硬件设备所表现出的一组**独特的、可识别的特征或属性**。资产识别系统通过将其在探测中观察到的特征与指纹库中的记录进行匹配，来确定资产的身份 。指纹库的质量和覆盖范围直接决定了资产识别的准确率。
> ![资产指纹识别流程示意图.png](https://images.mauga.top/2025/10/fcb1f39523a6167bfdae015f7fe238d3.png)

##### 基于特征匹配的指纹识别
资产指纹识别技术可以根据其分析的数据层面进行分类：
1. **服务Banner抓取**：这是最简单直接的指纹识别方法。许多网络服务在建立连接时会主动发送一个“Banner”字符串，其中通常包含软件名称和版本号，例如SSH服务的`SSH-2.0-OpenSSH_8.2p1`或FTP服务的`220 ProFTPD 1.3.5 Server`。直接捕获并解析这些Banner，就可以快速识别服务
2. **协议级指纹识别**：当Banner信息缺失或被伪造时，需要更深入地分析协议实现的细节
	- **TCP/IP协议栈指纹**：不同操作系统（如Windows, Linux, macOS）的TCP/IP协议栈在实现上存在细微差异。通过向目标发送一系列精心构造的、甚至是畸形的TCP/IP数据包，并观察其响应（如初始TTL值、TCP窗口大小、对特定标志位的响应等），可以高精度地推断出其操作系统类型。这是Nmap操作系统识别功能的核心原理
	- **TLS/SSL指纹**：即使流量被加密，TLS握手过程本身也暴露了大量可用于指纹识别的信息。客户端在`ClientHello`消息中会宣告其支持的TLS版本、密码套件（Cipher Suites）、扩展（Extensions）和椭圆曲线等参数。不同的客户端库（如Java、Python的requests、Go、浏览器内核）和版本会以特定的顺序和组合提供这些参数。通过对这些参数进行哈希计算（如**JA3/JA3S算法**），可以生成一个能够高精度识别客户端应用甚至恶意软件家族的指纹 。这对于在加密流量中识别应用和威胁至关重要
3. **应用层指纹识别**：针对特定的应用协议，尤其是HTTP
	- **Web指纹**：通过分析Web应用的特定行为和文件来识别其身份。常见技术包括：**计算特定文件的哈希值**（如`favicon.ico`、`robots.txt`、特定的CSS或JS文件）、检查HTTP响应头中的特定字段（如`Server`、`X-Powered-By`）、在HTML源码中搜索特定的注释或元标签、以及分析特定URL路径的响应内容。这些特征可以精确地识别出是WordPress、Joomla、Drupal还是Jenkins、Tomcat等应用
4. **设备指纹识别（IoT/OT）**：这是==指纹识别领域的一个重要前沿==，目标是识别物理硬件设备。由于物联网（IoT）和运营技术（OT）设备种类繁多，且常使用专有协议，识别难度较大。其指纹通常是==多维特征的组合==，例如：特定的开放端口组合、专有协议的响应模式、独特的设备管理界面（Web界面指纹）、以及嵌入在各种协议Banner中的厂商或型号信息等
##### 基于行为分析的指纹识别
传统的指纹识别技术本质上是一种**静态特征匹配**。它依赖于一个预先构建的、庞大的已知特征库。这种模式面临着两个日益严峻的挑战。首先，它陷入了一场与防御者的“军备竞赛”：有安全意识的系统管理员可以轻易地修改或隐藏服务Banner、HTTP头等明显的静态特征，从而使简单的指纹匹配失效。其次，物联网和云原生技术的爆炸式发展催生了海量的新设备和新应用，其特征层出不穷。手动为这些新资产创建和维护静态指纹库变得越来越不切实际，指纹库的更新速度永远追不上新资产出现的速度。
这些挑战推动了资产识别技术向一个更高级的范式演进：**行为分析（Behavioral Analysis）**。这种方法的思路转变是根本性的：它不再问“这个资产**呈现**了什么静态特征？”，而是问“这个资产在网络上**如何行为**？”。它不再依赖于单一的、易变的特征，而是==通过机器学习模型来学习和识别一个资产在一段时间内的通信模式==，例如
- 数据包长度的统计分布
- 数据包到达的时间间隔（Inter-arrival Times）
- 通信协议的使用频率和顺序
- 连接的持续时间
- 数据流的字节熵
通过对这些时间序列特征进行建模，可以为每种类型的设备（例如，一个特定型号的IP摄像头、一个特定的PLC控制器）生成一个独特的“行为指纹”。这种方法的优势在于其**鲁棒性**和**适应性**。**行为指纹很难被刻意伪造**，因为它根植于设备固件和软件的底层工作方式。更重要的是，通过无监督或半监督学习，这种方法能够发现和聚类**未知**的设备类型，而无需预先拥有它们的静态指纹。这对于应对层出不穷的新型IoT/OT设备构成的安全挑战具有至关重要的意义。
### 数据分析
> 在通过网络资产探测阶段获取网络空间中基础设施、用户、服务等资产的属性信息后，在分析阶段需要发现、还原它们之间的逻辑、物理及功能性关系。它更关注资产与资产之间的关系
> ![资产属性关联图.png][https://s.secrss.com/anquanneican/1a0b9be561ad5366923928ec594a232b.png]
#### 资产关联分析
资产关联分析旨在挖掘不同网络资产之间的潜在关联关系,包括物理连接、  逻辑连接、业务依赖等多种形式。通过构建资产间的关联模型,可更全面地理解  网络的整体架构,识别关键节点与依赖链条,评估单点故障可能引发的连锁影响,  进而揭示潜在的安全风险传播路径。
#### 资产与组织关联映射分析
资产与组织关联映射分析旨在将网络资产与所属的组织实体(如部门、业务  单元、公司等)进行关联和映射。通过这种分析,可以更好地了解组织对资产的  使用和管理情况,评估不同组织部门的安全风险,以及在发生安全事件时能够快  速定位责任主体。例如下图所示：
![资产与组织关联映射分析的示例图.png](https://images.mauga.top/2025/10/4cf44b1dee214db89856ca3a407247a9.png)

#### 资产定位
资产定位是指在网络空间中准确确定网络资产的物理位置、逻辑位置以及所  属组织等信息的过程。准确的资产定位有助于网络安全管理者了解资产分布,制  定合理的安全策略,提高应急响应效率。
资产定位的总体流程,包括**数据采集、数据处理、位置推断和结果验证等环节**。数据采集模块负责收集各种与资产位置相关的信息,如 IP 地址、网络流量、基站信号等；数据处理模块对采集到的数据进行清洗、转换和特征提取；位置推断模块根据处理后的数据，利用各种定位算法确定资产的位置；结果验证模块对定位结果进行准确性评估和修正。
![资产定位总体流程.png](https://images.mauga.top/2025/10/28c053e8b6e7c04567a2441fd549831f.png)

#### 威胁建模
威胁建模是一种识别、评估和分析网络系统**面临的潜在威胁**的过程。通过构建威胁模型，网络安全人员可以更好地了解系统的安全弱点，提前制定应对措施，降低安全风险。
威胁建模的基本流程，主要包括系统分析、威胁识别、威胁评估和模型建立四个步骤。系统分析阶段主要对目标系统的架构、功能、资产分布等进行全面了解；威胁识别阶段通过各种手段收集和分析潜在的威胁信息；威胁评估阶段对识别出的威胁进行量化评估，确定其严重程度和影响范围；模型建立阶段根据前三个阶段的结果，构建威胁模型，并将其应用于安全决策和防护措施的制定。
![威胁建模的基本流程.png](https://images.mauga.top/2025/10/e473a4e78906d9537d81f50471ca727d.png)

#### 漏洞与暴露面分析
漏洞与暴露面分析是网络空间测绘的重要组成部分，其主要目标是识别网络中存在的安全漏洞以及系统对外暴露的攻击面，从而为网络安全防护提供有力支持。
![多源数据融合的漏洞与暴露面分析过程.png](https://images.mauga.top/2025/10/008106748c8e5c48a753be4a7f4be292.png)

### 可视化
#### 可视化模型

##### 地理空间强相关模型
地理空间强相关模型是指**网络空间资产与地理空间位置具有明确且紧密联系**的一种可视化表达模型。在这种模型中，网络资产的地理位置信息是可视化的重要基础，它能够将网络空间中的资产直观地映射到现实地理空间中，使得用户可以清晰地看到不同地区的网络资产分布情况。该模型通常**结合地理信息系统(GIS)技术**实现网络资产的空间可视化。首先，收集网络资产的地理位置信息，这可能包括 IP 地址对应的地理坐标(可以通过专业的 IP 定位数据库获取)、数据中心的实际物理地址等。然后,将这些信息与地理地图相结合，在地图上以不同的图标、颜色或标记来表示不同类型的网络资产。
##### 地理空间弱相关模型
地理空间弱相关模型并不强调网络空间资产与具体地理位置的精确映射关系，而是侧重于展示网络资产之间的某种抽象的、与地理空间有一定关联的关系。例如，它可能关注的是不同地区网络资产之间的**流量交互关系、业务关联关系**等，而不是资产具体位于哪个经纬度。
##### 拓扑图
在网络空间测绘中,拓扑图可以展示网络资产(如服务器、路由器、交换机等)之间的物理或逻辑连接关系，帮助用户直观地理解网络的结构和布局。包括反映网络中设备的实际物理连接情况的**物理拓扑图**和侧重于展示网络中各组件之间的逻辑关系，如数据流向、通信协议等的**逻辑拓扑图**。
#### 地图构建流程
1. **数据采集**：除了资产探测获取的IP、端口、服务等信息外，测绘还需要采集专门用于揭示关系的数据。如
	-  **路径信息**：使用`traceroute`等工具获取IP间的路由路径 。  
	-  **路由信息**：收集全球BGP路由表数据，了解自治系统（AS）级别的连接关系 。  
	-  **DNS数据**：大规模采集和分析DNS记录，建立域名、子域名与IP地址之间的映射关系 。  
	-  **配置与流量数据**：在有权限的环境下，分析网络设备配置文件、云环境元数据和网络流量日志，可以直接揭示资产间的依赖关系。
2. **关系建模与结构还原**：这是测绘的核心技术环节。包括：
	- **IP级拓扑还原**：基于`traceroute`数据，构建IP路径图，识别网络中的关键路由器和链路
	- **AS级拓扑还原**：基于BGP数据，构建全球AS连接图，并分析AS之间的商业关系（如对等Peering、客户-提供商Customer-Provider）
	- **逻辑关系还原**：通过分析DNS CNAME/MX记录、HTTP重定向、API调用关系、证书使用者备用名称（SAN）字段等，还原应用层面的逻辑依赖关系。
	- **物理结构还原**：结合IP定位、PoP（Point of Presence）点识别等技术，将逻辑节点映射到物理设施和地理位置上。
3. **多维情境化**：构建多层次的网络空间地形图：
	- **地理空间映射**：将网络资产和拓扑结构投射到地理地图上，直观展示网络基础设施的全球分布、数据流动的跨境路径等
	- **组织与社会维度**：将资产与其所有者（组织、个人）进行关联，并可进一步关联到社会、经济、政治等宏观背景信息
	- **安全维度**：在拓扑图上标注资产的漏洞信息、威胁情报、实时安全告警等，形成一张动态的网络安全态势图
#### 网络空间地形
##### 网络空间地形定义
在传统军事学中，地形分析是作战规划的基础。经典的**OACOK**框架被用来评估物理战场：
- **O**bservation and fields of fire (观察与射界)
- **A**venues of approach (接近路线)
- **C**over and concealment (掩蔽与隐蔽)
- **O**bstacles (障碍)
- **K**ey terrain (关键地形)

网络空间与实际物理地形存在一些根本差异，主要是如下几点：
1. **人造性与可塑性**：物理地形（如山脉、河流）是自然形成且相对恒定的。而网络空间地形完全是人造的，由硬件、软件和协议构成。它不仅可以被构建，还可以被迅速地重新配置。防火墙规则的修改、路由策略的变更，都可能在瞬间改变“地形” 。这更类似于对城市环境的分析，而非野外战场。  
2. **动态性与瞬时性**：物理地形的变化以地质年代或至少是季节为尺度。网络空间中的“地形元素”——如IP地址分配、DNS解析结果、网络路径——可能在几小时甚至几秒钟内就发生变化 。 
3. **分层性与抽象性**：物理地形是三维的、连续的。网络空间地形则是多层次的、离散的。它同时存在于多个逻辑层面：
    - **物理层**：数据中心、光缆、卫星等物理基础设施。
    - **网络层**：IP地址、子网、路由器、AS等构成的网络拓扑。
    - **应用层**：Web服务、API接口、数据库等构成的应用架构。
    - **角色层（Persona Layer）**：用户账户、电子邮件地址、社交媒体身份等虚拟角色构成的网络 。 
##### 网络空间关键地形
1. **网络关键地形（Key Terrain - Cyber, KT-C）**：根据美国联合参谋部条令的定义，关键地形是指**任何控制权能为交战双方中任意一方提供显著优势的地点或区域** 。在网络空间中，这指的是那些具有全局性或系统性重要性的资产、系统、服务或基础设施。KT-C的价值是**任务无关**的，其重要性源于其在网络生态系统中的核心地位。例如：
	-  一个国家的根域名服务器（Root DNS Servers）。
	- 一个大型云服务商的核心身份认证系统。
	- 跨国海底光缆的登陆站。
	- 广泛使用的代码托管平台或软件包仓库。
	控制这些KT-C，意味着能够对大范围的网络活动产生深远影响
2. **任务相关网络地形（Mission-Relevant Terrain - Cyber, MRT-C）**：这是指对于**成功执行某项特定任务**至关重要的那部分网络地形 。MRT-C的价值是**上下文相关**的，它完全取决于任务目标。如：
	- **任务目标**：窃取A公司的商业计划书。
	- **MRT-C可能包括**：A公司的VPN网关、内部文件服务器、存储计划书的数据库、以及能够访问这些系统的特权用户账户。
	- **任务目标**：瘫痪B国电网。
	- **MRT-C可能包括**：B国电网的调度中心网络、远程终端单元（RTU）、以及用于下发指令的工控协议。
这种区分对于攻防双方的资源分配和战略规划具有决定性意义。==防御方==需要识别并优先保护其所有的**关键地形（KT-C）**，因为它们是系统性风险点。而==攻击方==则会专注于识别和攻击与其目标直接相关的**任务相关地形（MRT-C）**，以最高效的方式达成目的。
#### 建模与可视化技术
将抽象的网络地形概念具象化，是网络空间测绘面临的核心挑战之一。这需要通过建模和可视化技术，将不可见的网络结构和关系转化为人类分析师可以理解和交互的“地图”。
- **分层建模**：由于网络地形的多层特性，单一的平面图无法有效表达。因此，研究人员提出了多种分层模型。这些模型通常将网络空间从下至上划分为地理层、物理网络层、逻辑网络层、虚拟角色层和实体人物层等，并研究各层内部的拓扑以及层与层之间的映射关系 。  
- **地理-网络融合（Geo-Cyber Integration）**：这是一种强大的可视化方法，它将逻辑上的网络资产（如IP地址、服务器）映射到其物理所在的地理位置，并将它们之间的网络连接（如数据流路径）在地理地图上进行可视化 。这种融合视图能够直观地揭示：  
    - 关键网络基础设施的地理集中区。
    - 跨国数据流动的路径和瓶颈。
    - 地缘政治因素与网络结构之间的潜在关联。
- **可视化技术**：为了呈现复杂的网络地形数据，研究人员和工程师采用了多种可视化技术：
    - **节点-链接图（Node-Link Graphs）**：最常用的拓扑表示法，用节点代表资产，用链接代表关系。通过调整节点大小、颜色和链接粗细，可以表达资产的重要性、类型或流量大小等属性 。  
    - **热力图（Heatmaps）**：在地理地图或逻辑拓扑图上，用颜色深浅来表示某一区域的事件密度，如攻击来源地、漏洞分布或网络流量 。  
    - **三维与沉浸式可视化**：利用3D空间来表示网络的分层结构，或者在虚拟现实（VR）环境中构建网络靶场，以提供更直观的交互和态势感知体验
#### 地形构建的价值
不同于物理地图的价值在于对现实世界的精确、静态复刻，考虑到网络空间的动态性，构建这样的网络地图不仅不切实际，而且其价值会迅速衰减。它的价值在于充当一个**动态的、可交互的决策支持系统**，其核心功能是实时回答运营和战略层面的关键问题，如 ：
- **影响分析**：“如果这台核心数据库被攻陷，其‘影响半径’有多大？会影响到哪些下游业务系统？”
- **攻击路径建模**：“从外部网络到核心数据资产，存在哪些可能的、最高危的攻击路径？”
- **弹性评估**：“网络架构中存在哪些单点故障？在遭受DDoS攻击时，哪些链路最有可能成为瓶颈？”

通过将实时资产数据、拓扑关系、漏洞情报和威胁告警融合在一张可交互的地图上，分析师可以进行攻击模拟、防御预演和风险评估，将其作为一个网络空间中进行”兵棋推演“的沙盘。
## 平台架构设计
> 网络空间测绘平台是实现网络空间测绘功能的重要载体

一个典型的网络空间测绘系统至少包含以下几个核心模块：
1. **任务管理与调度：** 负责生成和分派扫描任务（要扫什么IP、什么端口、什么协议）。
2. **数据采集（探针）：** 分布在全球各地的高性能扫描节点，执行实际的探测和数据抓取（Banner、证书、服务指纹等）。
3. **数据处理（管道）：** 对海量的原始数据进行清洗、解析、指纹识别、关联分析。
4. **数据存储：** 存储 PB 级的资产数据、指纹数据、漏洞数据，并提供高效检索。
5. **数据分析与智能（AI/ML）：** 资产画像、漏洞关联、威胁情报生成、网络拓扑分析。
6. **应用与服务（API/Web）：** 向用户提供数据检索、可视化和订阅服务。
### 分层设计思想
> 分层架构也被称为”N层架构“，是最经典、最基础的软件架构设计之一，其核心点为”**关注点分离**“，将一个复杂的系统从逻辑上水平切割成多个“层”，每一层都有明确定义的职责，并且只与相邻的层进行通信。

![网络空间测绘平台的分层架构示意.png](https://images.mauga.top/2025/10/4ac3db060e9dd048712df9591cd60a43.png)

1. 数据采集层：该层是平台数据的来源，主要负责对目标网络空间的资产进行探测和数据收集。它使用各种探测技术，如 IP 活跃性探测、端口开放性探测、服务扫描等，收集网络设备和系统的基础信息。
2. 分析引擎层：对采集到的数据进行深度挖掘和分析。运用资产关联分析、资产与组织关联映射分析、威胁建模、漏洞与暴露面分析等技术，从海量数据中提取有价值的信息，发现潜在的安全威胁和资产关系。
3. 可视化层：将分析结果以直观的方式展示给用户。利用地理空间强/弱相关模型、拓扑图等可视化技术,让用户能够快速理解网络资产的分布、关系和安全态势。
4. 应用接口层：为外部系统和用户提供访问和调用平台功能的接口。通过 API 等方式，实现与其他安全系统、业务系统的集成，方便用户根据自己的需求进行定制开发和应用拓展。

问题在于，该架构只能部署为单体应用，仅适用于小规模的、特定目标的测绘工具。它具有如下缺陷：
- **完全无法扩展：** 测绘系统的核心瓶颈在于数据采集和处理。在单体架构下，无法独立扩展处理管道。如果扫描量激增导致数据处理CPU跑满，唯一的办法是再部署一套完整的系统（包括 Web 界面和 API），这极其低效。
- **性能瓶颈：** 所有的原始扫描数据都涌向中心化的业务逻辑层和数据访问层，形成巨大瓶颈。
- **技术栈僵化：** 在单体应用架构下，几乎无法利用多语言的优势， 例如用 C/Go 来写高性能探针，用 Python 来做 AI 分析，用 Java 来写稳定的业务逻辑。
- **可靠性差：** 任何一个环节都可能导致整个测绘系统崩溃。
### 微服务架构
> 微服务架构是作为对单体应用（及其常见的分层结构）弊端的一种回应而出现的，是“关注点分离”原则在服务维度的极致体现。微服务架构将网络空间测绘平台拆分成多个小型、自治的服务。每个微服务专注于单一的业务功能，例如数据采集微服务、资产关联分析微服务、可视化展示微服务等。这些微服务可以独立开发、部署和扩展。微服务之间通过轻量级的通信机制(如 RESTful API、消息队列等)进行交互。

![网络空间测绘平台的微服务架构示意.png](https://images.mauga.top/2025/10/5d35a10d21958e18d4a3affca364b9ea.png)

微服务架构具有极高的敏捷性、强大的可扩展性（可以针对性地扩展瓶颈服务）、故障隔离、技术选型灵活。但是需要考虑如下问题：
- **分布式系统复杂性：** 现在不再是进程内调用，而是跨网络的 RPC 调用。这引入了网络延迟、服务发现、负载均衡、容错等一系列问题。
- **运维复杂度剧增：** 需要管理和监控成百上千个服务实例。**“可观测性” (Observability)**（包括日志、指标、**分布式追踪 - Distributed Tracing**）变得至关重要。
- **数据一致性：** 如何在多个服务（多个数据库）之间保持数据一致性？这通常需要放弃强一致性（ACID），转而采用 **“最终一致性” (Eventual Consistency)**，并使用如 **“Saga 模式”** 或 **“事件溯源” (Event Sourcing)** 等复杂模式来管理分布式事务。
- **服务边界划分：** 如何正确地划分服务边界？这是微服务设计中最困难的问题。划分过粗，得到的只是“分布式单体”；划分过细，又会导致服务间通信风暴。
### 云原生架构
> 云原生架构是一种专门设计用于在云环境中构建和运行应用程序的方法。它充分利用了云计算模型的优势：**弹性、分布式、自动化、按需服务**。

![网络空间测绘平台的云原生架构示意.png](https://images.mauga.top/2025/10/b8d99f29a85d5ef7a41b68c14430e3cb.png)

常见的云计算模式包括**基础设施即服务(IaaS)**、**平台即服务(PaaS)** 和**软件即服务(SaaS)**。在网络空间测绘中,可以使用 IaaS 提供的虚拟服务器、存储设备等资源来部署数据采集、分析和存储系统；使用 PaaS 提供的开发和运行环境来开发和运行分析算法和应用程序；使用 SaaS 模式向用户提供网络空间测绘服务。例如，利用 Amazon Web Services(AWS)的 EC2 实例来运行数据采集工具和分析引擎，使用 S3 存储采集到的数据和分析结果，用户可以通过浏览器访问基于 SaaS 的网络空间测绘平台获取相关信息。
云原生架构具有极致的弹性（按需扩缩容，节省成本）、高可用性（利用云厂商的全球基础设施）、免运维（尤其在 PaaS 和 FaaS 模式下）、按需付费等优点。
### 总结
这三种架构并非总是相互排斥的。例如，一个运行在“云计算架构”平台上的应用，其本身很可能采用了“微服务架构”的设计，而单个微服务内部又可能遵循“分层架构”的逻辑。一个现代的、具备高扩展性和高性能的网络空间测绘系统，其理想架构是”**基于云原生的微服务架构**“：
1. **逻辑架构：** 采用 **微服务架构**。这是满足测绘系统高内聚、低耦合、独立扩展需求的必然选择。
2. **物理/平台架构：** 采用 **云原生架构**。这是让微服务架构得以在超大规模下（全球探针、PB 级数据）经济、高效、可靠运行的基础设施底座。
3. **内部设计：** 在单个微服务内部，可能仍然会使用 **分层架构**来组织其内部代码逻辑。
## 网络空间搜索引擎
> 网络空间搜索引擎是将上述技术大规模运用到全球网络并持续化运营，以服务形式向公众或客户提供的平台，用户在使用这些平台时，通常**不是在进行一次实时的网络扫描**，而是在**查询一个庞大的、预先构建好的数据库**。

从分层架构角度来说，这些平台的通用架构通常包含三个核心组件：
1. **分布式探测网络**：在全球不同地理位置部署大量的探测节点（Probes）。这些节点7x24小时不间断地对整个IPv4地址空间（以及部分IPv6空间）进行扫描，**执行主机发现、端口扫描和指纹抓取**等任务 。探测网络的分布式特性有助于提高扫描效率并绕过地理性的网络封锁。  
2. **数据处理与索引管道**：探测节点收集到的海量原始数据被汇集到后端。一个复杂的数据处理管道负责对这些数据进行解析、清洗、标准化、**指纹匹配和富化**（例如，关联地理位置和漏洞信息）。处理后的数据被加载到专门为高速检索优化的大规模搜索引擎（如Elasticsearch）中，**建立索引** 。  
3. **用户查询与API接口**：平台向用户提供一个Web界面和一套API，用户可以通过特定的查询语法来检索数据库中符合条件的资产 。

**主流的网络空间搜索引擎对比：**

| 特性         | Shodan                           | FOFA                          | ZoomEye (钟馗之眼)           | Censys                              |
| ---------- | -------------------------------- | ----------------------------- | ------------------------ | ----------------------------------- |
| **来源/侧重**  | 美国，2009年。侧重IoT/ICS和全球基础设施。       | 中国。侧重Web资产、漏洞快速响应、灵活语法。       | 中国，2013年。侧重全面资产发现、应用层探测。 | 美国，学术背景。侧重协议深度分析、证书生态。              |
| **数据覆盖量**  | 约4.36亿设备 (2020年数据)               | 约27万设备 (2020年数据，可能统计口径不同)     | 约11.9亿设备 (2020年数据)       | 约1.11亿设备 (2020年数据)                  |
| **协议支持**   | 广泛，覆盖约185种协议，特别关注工控协议。           | 较广，覆盖约116种协议，特别关注Web相关协议。     | 最广，声称支持超过550种协议。         | 较少，约34种，但对支持的协议进行深度解析。              |
| **扫描频率**   | 较高。热门端口（如80/443）约9-10天。          | 较低。HTTP约39天，HTTPS约102天。       | 较低。HTTP约389天，HTTPS约26天。  | 最高。HTTPS每日扫描，HTTP/FTP等约2天。          |
| **核心优势**   | 成熟的生态系统，强大的ICS/IoT探测能力，丰富的第三方集成。 | 强大的查询语法，快速的漏洞指纹更新，深入的Web组件识别。 | 庞大的设备发现总量，深入的应用层指纹识别。    | 每日更新的HTTPS数据，全面的证书搜索与分析，学术研究级的数据质量。 |
| **API与限制** | 提供付费API，免费使用受限。                  | 提供会员制API，功能和配额与等级挂钩。          | 提供会员制API，功能和配额与等级挂钩。     | 提供免费的社区版API和付费的商业API，面向研究人员友好。      |
# 网络空间测绘生命周期
将网络空间测绘视为一个线性的三阶段过程（资产探测、数据分析、可视化）是早期学术研究中的一种普遍视角，它有效地描述了如何创建一张静态的网络空间“地图”。然而，随着云计算、物联网（IoT）和持续集成/持续部署（CI/CD）等技术的普及，网络环境的动态性、短暂性和复杂性急剧增加。网络资产不再是静态的，它们可以被即时创建、配置、移动和销毁。这种演变使得静态的测绘模型在实践中显得力不从心。现代安全范式，特别是攻击面管理（Attack Surface Management, ASM），提供了一个更为贴切的框架 。一个更精确的模型是**网络空间测绘生命周期**，它与ASM的持续性、周期性理念保持一致。该生命周期包含四个关键且相互关联的阶段：
1. **资产发现与分类 ：** 此阶段是持续性的基础。其目标是利用自动化工具和技术，不间断地识别和映射组织的所有互联网可达资产 。这不仅包括已知的、注册在案的服务器和应用，更关键的是要发现那些未经授权的“影子IT”（Shadow IT）和被遗忘的“僵尸资产”（Orphaned Assets）。发现过程利用与攻击者相似的高级侦察技术，确保覆盖范围的全面性 。一旦资产被识别，就需要进行初步分类，根据其类型（如Web服务器、数据库、API端点）、关键性（如核心业务系统、开发测试环境）和敏感性进行标记 。
2. **风险评估与漏洞管理：** 在清晰的资产清单基础上，组织需要对每个资产进行全面的风险评估，以识别潜在的攻击向量 。此阶段融合了多种技术，包括自动化的漏洞扫描、配置审计、软件成分分析（SCA），以及与威胁情报的集成 。通过将资产的特定属性（例如，运行的软件版本、开放的端口、配置状态）与已知的漏洞数据库（如CVE）和威胁情报源进行关联，安全团队可以清晰地了解其面临的网络风险因素 。
3. **优先级排序与修复：** 由于资源限制，安全团队不可能同时修复所有已发现的漏洞和风险。因此，优先级排序至关重要。此阶段的核心是将上下文信息应用于风险评估结果，以确定修复的先后顺序。优先级通常基于多种因素，包括漏洞的可利用性（例如，是否存在公开的利用代码）、潜在的业务影响（该资产是否支持关键业务流程）、以及该漏洞是否已被活跃的攻击活动所利用 。有效的优先级排序能够确保有限的安全资源被投入到最关键的风险点上。
4. **持续监控与适应：** 网络的攻击面是不断变化的 。新的设备上线、软件更新、配置更改、云资源的动态伸缩，都会引入新的风险。因此，测绘生命周期必须是闭环的。持续监控意味着定期或实时地重复前述的发现和评估过程，以确保资产清单和风险画像始终保持最新 。当环境发生变化或出现新的威胁时，整个生命周期会重新迭代，以适应新的安全态势。
# 挑战与前沿技术
## 多源数据融合
### 为什么需要多源数据融合
在复杂的网络环境中，任何单一的数据来源都只能提供一个片面的、不完整的视角。例如，主动扫描能看到开放的端口，但看不到实际的流量；DNS数据能揭示域名与IP的映射，但不知道承载的应用；威胁情报能指出某个IP是恶意的，但无法说明它在目标网络中的具体角色。**多源数据融合（Multi-Source Data Fusion）** 正是为了解决这一难题而生，其目标是将来自**不同来源**、**不同类型**、甚至相互矛盾的数据整合起来，每一种数据源都提供了对网络空间某一维度的独特视角，它们的融合共同构建了一个远超任何单一来源所能提供的、更为全面、正确和立体的视图，包括：
- **提高准确性**：通过交叉验证来自不同来源的信息，可以纠正单个数据源的错误或偏差。
- **增加确定性**：综合多个不完整的信息片段，可以拼凑出更完整的图像，减少认知盲区。
- **生成新洞见**：将不同维度的数据（如网络拓扑数据与业务逻辑数据）相结合，可以发现隐藏在单一数据集中无法察觉的深层关系和模式。
### 多源数据融合层次
> 借鉴信息融合领域的经典理论，将其分为三个主要层次。这三个层次代表了从原始数据到最终决策的不同抽象级别，在网络空间测绘的实践中，它们共同构成了一个完整的数据处理与分析流程 。

1. 数据层融合：融合过程的最底层，它直接对来自不同传感器的原始数据进行合并 。其核心目标是在不进行大量预处理或特征提取的情况下，创建一个统一的、包含所有原始信息的数据集。在测绘过程中，通常意味着将不同来源的原始日志**按照时间戳对齐**，形成一个统一的事件时间序列 。
	- 优势：最大限度地保留了原始信息的完整性和细节，为后续的深入分析提供了最丰富的数据基础。
	- 劣势：数据层融合面临着巨大的挑战。计算和存储成本极高，并且原始数据往往充满噪声、格式不一且可能存在数据缺失。因此，在构建大规模网络空间地图的场景中，纯粹的数据层融合并不常见，它更多地应用于小范围、高精度的事件调查分析。
2. 特征层融合：特征层融合是网络空间测绘领域中应用最广泛、最核心的融合方法。首先从各个独立的原始数据源中提取出有意义的、结构化的特征，然后将这些来自不同源的特征向量组合成一个更全面的、信息更丰富的统一特征向量，用于描述同一个实体（如一个IP地址或一个域名）。
	- 优势：在保留关键信息的同时，通过特征提取大大压缩了数据量，显著降低了计算和存储的复杂性 。它将异构的、非结构化的原始数据转化为了同构的、结构化的特征，为后续的机器学习、数据库查询和关联分析提供了便利。
	- 劣势：该方法的成功与否高度依赖于特征提取的质量。如果特征提取过程丢失了关键的原始信息，那么这种损失在后续的分析中将无法弥补 。“特征工程”的优劣直接决定了最终分析结果的上限。
3. 决策层融合：决策层融合是最高层次的融合，它处理的是==来自不同分析模型或信息源的“决策”或“结论”==。在此层次中，每个数据源或分析模块都独立地对目标进行处理，并得出一个初步的判断（例如，“高风险”、“疑似恶意”、“正常”）。然后，一个更高层次的融合引擎会根据预设的规则（如投票机制、加权平均）或更复杂的模型（如贝叶斯推理、D-S证据理论）来综合这些独立的决策，==从而得出一个最终的、通常更可靠的全局性结论== 。
	- 优势：这种方法具有很强的鲁棒性和容错性。即使某个底层分析模型出现故障或产生错误决策，融合引擎仍然可以根据其他模型的输出来做出相对正确的最终判断。它还非常灵活，易于集成新的分析模型。
	- 劣势：在融合之前，大量中间过程信息和原始数据细节已经被丢弃，只剩下高级别的决策，因此可能会造成信息损失。
在网络空间测绘的宏观构建中，**特征层融合**扮演了基石的角色。它解决了如何从海量、异构的原始信号中**构建一个结构化、可查询的资产数据库**的核心问题。而数据层和决策层融合则更多地在特定分析场景和实时安全运营中发挥作用，作为对特征层融合所构建的资产知识库的补充和应用。
### 多源数据融合流程
#### 数据采集
在网络空间测绘中，常见的可采集数据如下：

| **数据源 (Data Source)** | **关键工具/协议 (Key Tools/Protocols)**                                             | **提供的信息 (Information Provided)**           | **采集方法 (Collection Method)** | **优势 (Strengths)**          | **弱点/偏差 (Weaknesses/Biases)**        |
| --------------------- | ----------------------------------------------------------------------------- | ------------------------------------------ | ---------------------------- | --------------------------- | ------------------------------------ |
| **主动端口扫描**            | ZMap, Masscan, Nmap, ZGrab                                                    | 存活主机、开放端口、服务指纹（Banner）、软件版本、配置详情           | 主动探测                         | 提供特定时间点的“地面实况”信息，准确性高       | 易被防火墙/IDS阻止；仅为时间快照；可能触发告警            |
| **被动DNS (pDNS)**      | DNS传感器, dnstap                                                                | 历史及实时的域名-IP映射关系（A, AAAA, CNAME, MX, NS等记录） | 被动观测                         | 提供历史上下文；揭示隐藏的基础设施；追踪域名变化    | 依赖传感器部署位置，存在覆盖偏差；数据可能存在延迟            |
| **BGP路由监控**           | BGP Monitoring Protocol (BMP), Route Collectors (e.g., RIPE RIS, Route Views) | IP前缀的自治系统（AS）归属、互联网路由路径、劫持和泄露事件            | 被动观测                         | 提供网络层的宏观所有权和连接性视图；识别大规模路由异常 | 粒度较粗，无法深入到主机层面；不反映内部网络结构             |
| **证书透明度 (CT) 日志**     | 公共日志服务器 (e.g., Google, Cloudflare)                                            | 所有公开签发的SSL/TLS证书，包含主域名和子域名                 | 监控公共日志                       | 主动发现新创建的子域名和网站资产；追踪证书生命周期   | 仅覆盖启用TLS的资产；无法发现未使用TLS的服务            |
| **WHOIS/RDAP**        | WHOIS协议, Regional Internet Registries (RIRs)                                  | 域名和IP块的注册人信息、联系方式、注册日期、DNS服务器              | 查询注册机构                       | 提供资产归属和所有权信息，有助于实体关联        | 信息常因隐私保护而隐藏或不准确；不能直接反映技术状态           |
| **威胁情报源**             | STIX/TAXII, 商业/开源情报API                                                        | 已知的恶意IP、域名、文件哈希、攻击者TTPs、C2服务器列表            | API/订阅源                      | 为发现的资产叠加风险上下文；识别已知的恶意活动     | 可能存在误报（False Positives）；情报具有时效性，可能过时 |
| **地理位置IP (GeoIP)**    | MaxMind, IP2Location等数据库                                                      | IP地址到物理位置（国家、城市、ISP）的映射                    | 数据库查询                        | 提供资产的地理分布视图；有助于识别异常的地理访问模式  | 精度不一，尤其在城市级别；VPN和代理会使其失效             |
#### 数据处理
##### 解析与标准化
Banner信息是文本形式的，但其格式因协议和软件而异。此阶段的核心任务是将这些文本解析成统一的键值对（key-value）格式。
1. **基于规则的解析**: 对于格式相对固定的Banner，如HTTP头，可以使用高效的正则表达式进行解析。
2. **基于NLP技术的解析**: 对于更复杂或格式多变的Banner，可以利用NLP技术包括LLM进行协议解析和漏洞信息提取
##### 特征提取与指纹化
仅仅解析Banner中的明文信息是不够的，因为很多设备会刻意隐藏或修改其版本信息。为了更可靠地识别资产，多数应用会采用指纹化技术
1. 指纹识别：识别特定技术或产品的独有且稳定的特征，这些特征可能不是简单的文本字符串，例如网站图标的哈希值、特定HTML页面结构中某个独有的CSS类名或注释、HTTP响应头字段的特定顺序和组合计算出的哈希值、TLS握手中JARM指纹等等。
2. 规则构建：平台将这些独特的特征组合起来，形成一个“**规则指纹**” 。通过搜索这个指纹，就可以识别出所有具有该类特征的资产。
#### 实体解析与融合
这是整个融合流程中最关键的一步，也是真正体现“融合”价值的地方。在这里，来自不同数据源、描述同一现实世界对象的碎片化信息被链接起来，形成一个统一、连贯的实体画像。
##### 定义核心实体
在进行解析之前，系统必须首先定义其数据模型的核心实体。在网络空间测绘中，这些实体通常包括：主机、域名、证书、组织、服务、软件、应用等。
##### 实体解析流程
融合的关键在于找到连接不同实体的“**主键**”或“**枢纽**”（Pivots），如以IP或域名为枢纽进行，以追踪一个假设资产`api.examplecorp.com`为例：
1. **初始信号 (来自pDNS)**: 一个被动DNS传感器记录到一条解析信息：`api.examplecorp.com` 在时间戳 `T1` 解析为IP地址 `203.0.113.50`。
	- **ER操作**: 系统创建或更新了两个实体：一个`Domain`实体 (`api.examplecorp.com`) 和一个`Host`实体 (`203.0.113.50`)。同时，在它们之间创建了一个`RESOLVES_TO`的关系，并附带时间戳属性。
2. **第二个信号 (来自主动扫描)**: 一个扫描节点对IP `203.0.113.50` 的443端口进行了ZGrab扫描。扫描返回了一个TLS证书（哈希值为`CERT_HASH_123`）和一个HTTP Banner，其中包含`Server: nginx/1.21.6`。
	-  **ER操作**: 系统找到了已存在的`Host`实体 `203.0.113.50`。它创建了一个新的`Software`实体 (`nginx/1.21.6`) 和一个新的`Certificate`实体 (`CERT_HASH_123`)。然后，它在`Host`和`Software`之间创建了`RUNS_ON_PORT(443)`的关系，并在`Host`和`Certificate`之间创建了`USES_CERT`的关系。
3. **第三个信号 (来自CT日志)**: 证书透明度日志监控器发现了一个新签发的证书，其哈希值为`CERT_HASH_123`，该证书的通用名称（CN）或主题备用名称（SAN）中包含了`api.examplecorp.com`和`internal-api.examplecorp.com`。
	- **ER操作**: 系统通过`CERT_HASH_123`这个唯一的标识符，找到了已存在的`Certificate`实体。它确认了该证书与`api.examplecorp.com`的关联，并发现了一个新的`Domain`实体`internal-api.examplecorp.com`，同时将这个新域名也与该证书关联起来。
4. **第四个信号 (来自WHOIS)**: 对`examplecorp.com`进行WHOIS查询，返回的注册组织是“Example Corporation”。
	- **ER操作**: 系统创建了一个`Organization`实体“Example Corporation”。通过解析域名结构，它识别出`api.examplecorp.com`和`internal-api.examplecorp.com`都隶属于根域`examplecorp.com`，从而在这两个`Domain`实体和`Organization`实体之间建立了`OWNED_BY`的关系。
##### 统一资产画像构建
经过上述实体解析过程，原本分散在四个不同数据源中的孤立信息点被成功地“缝合”在了一起。现在，当用户查询`api.examplecorp.com`或`203.0.113.50`时，系统可以呈现一个统一且丰富的视图：_“组织‘Example Corporation’拥有域名`examplecorp.com`。该域名下有两个已发现的子域：`api.examplecorp.com`和`internal-api.examplecorp.com`。其中，`api.examplecorp.com`当前解析到IP地址`203.0.113.50`。该IP地址的443端口上运行着`nginx/1.21.6`服务，并使用了证书`CERT_HASH_123`，该证书同时还覆盖了`internal-api.examplecorp.com`。”_
#### 数据富化与分析
数据融合并形成统一视图后，其价值需要通过进一步的丰富化和分析来体现，将其转化为可直接用于安全决策的情报。
##### 漏洞映射
这是最直接的应用之一。系统将从Banner中解析出的结构化软件信息（如`product: "OpenSSH"`, `version: "8.2p1"`）与漏洞数据库（NVD）等权威漏洞库进行自动化比对。如果发现该版本的OpenSSH存在已知的CVE漏洞，系统就会自动为该资产打上相应的CVE标签。这使得用户不仅能看到资产上运行的服务，还能立刻了解其已知的安全风险。
##### 威胁情报融合
数据库中的核心标识符（IP地址、域名、证书哈希等）会与内外部的威胁情报源进行持续的比对。如果一个IP地址出现在某个知名的C2服务器列表中，或者一个域名与已知的钓鱼活动相关联，该资产就会被标记为高风险 。这种叠加使得地图不仅反映了资产的“状态”，还反映了其“信誉”和当前所处的“威胁环境”。
#### 索引与查询
最终，所有这些被融合、关联、丰富化的数据被“拍平”（Flatten）并存入一个大规模的搜索引擎索引中（如 Elasticsearch 或 ClickHouse）。
### 关键技术
#### 实体解析
“如何识别不同数据源中指向同一实体的重复记录” 是ER的核心问题，也称为数据去重（Deduplication）或记录链接（Record Linkage）。传统的Fellegi-Sunter 模型是**记录链接（Record Linkage）领域的经典统计模型**，通过分析两条记录中**关键字段的匹配程度**，计算它们属于 “同一实体（匹配对，Match）” 或 “不同实体（非匹配对，Non-match）” 的概率，再基于概率阈值决策是否匹配。具体来说，将记录（如 WHOIS）分解为多个字段（Organization, Email, Address）后，对每个字段使用不同的相似度函数（如 Jaro-Winkler 距离用于字符串，编辑距离用于域名）。通过**权重学习**学习每个字段在“匹配”决策中的重要性，最后计算一个总的匹配分数，超过阈值则判为“匹配”。
也可以使用基于深度学习的技术进行实体的解析，例如使用LLM或其他预训练模型将记录的关键字段转换为高维向量，通过计算向量的余弦相似度来判断它们语义上是否指向同一实体。这种方法能更好地处理缩写、别名和拼写错误。
#### 知识图谱
网络安全知识图谱（Cybersecurity Knowledge Graph, CKG）将通过实体解析关联起来的数据，以一种更形式化、更强大的方式进行组织。
构建CKG的过程，就是将融合后的资产画像转化为一个图数据库（如Neo4j, JanusGraph）中的节点和边的集合。其中节点代表核心实体，例如`Host` (属性: `ip_address`, `asn`, `country`)、`Domain` (属性: `domain_name`)、`CVE` (属性: `cvss_score`, `description`)、`Software` (属性: `product`, `version`)、`Organization` (属性: `name`) 等；边代表实体之间的关系。例如，`(Domain)-->(Host)`、`(Host)-->(Software)`、`(Software)-->(CVE)`、`(Domain)-->(Organization)` 。
一旦数据被构建成图谱，我们就可以利用图查询语言（如Cypher）和图算法进行传统数据库难以实现的复杂关联分析，例如：
- **复杂查询示例**: "查找所有由‘Example Corporation’拥有，且运行着受Log4j漏洞（CVE-2021-44228）影响的软件版本，并且该服务暴露在互联网443端口上的主机。" ，或者“找到所有和这个 C2 域名（`tracker.badguy.net`）共享同一个 SSL 证书序列号，并且注册邮箱后缀为 `.ru` 的 IP”，这种多跳转、跨实体类型的查询在图数据库中可以非常高效地完成，而传统数据库（如 SQL）很难回答。
- **图嵌入与相似性分析**: 更进一步，可以应用图嵌入（Graph Embedding）技术，如Node2Vec或GraphSAGE，将图中的每个节点$(h,t)$和关系$(r)$映射到一个低维向量空间中$(embedding)$ 。优化的目标是如果$(h,r,t)$这种关系三元组存在，如$(IP\_A, resolves\_to, Domain\_B)$，那么它们对应的向量应该满足$v_h+v_r\approx v_t$。这样做的好处是，可以用数学方式量化实体间的“相似性”。例如，使用训练好的模型进行推理，实现链接预测，可以计算出哪些资产在拓扑结构、运行服务、配置等方面与一个已知的被攻陷主机“最相似”，从而主动发现潜在的、具有相似风险特征的资产。
### 挑战与进展
#### 时态知识图谱（Temporal Knowledge Graphs, TKG）
> 在数据层面，资产的属性和关系是高度动态的。今天的 IP 属于 AWS，明天可能就释放回了地址池。如果融合模型不包含**时间维度**，就会产生“数据陈旧”（Staleness）问题，将一个已经不存在的漏洞关联到一个早已更换了主机的 IP 上。此外，在实体解析中，也存在时间冲突与一致性问题。

TKG不再将图视为静态快照，而是将其建模为一系列事件的集合。知识图谱中的每个事实（三元组）被赋予时间戳或时间区间，即$(h,r,t,\tau)$。图的节点、边以及它们的属性都会随时间变化 。TGN的核心思想是为每个节点维持一个“记忆”（memory）状态，该状态会根据与该节点相关的新事件（如新的连接、属性变化）进行更新。这使得模型能够学习到复杂的时序依赖关系 。相关技术包括：
1. 流式图处理。使用 Flink, Kafka Streams 等平台，在数据流入时实时更新图谱的边和属性
2. **TKG 嵌入模型：** 发展出如 `TTransE`, `RE-NET` 等模型，它们学习实体的“时变”向量表示，能够捕捉资产的演化规律。
#### 基于图神经网络的异构数据融合和知识推理
> 不同来源的数据具有多种数据格式， Banner 文本、JSON 格式的 API 返回、CSV 格式的 BGP 列表、X.509 证书的 ASN.1 结构、甚至图片（Favicon）。将这些**异构（Heterogeneous）** 数据统一到同一个语义空间是巨大挑战。

GNN（如图卷积网络 GCN、图注意力网络 GAT）已成为融合异构数据的利器，其核心思想是“消息的传递”，一个节点（如 `IP`）的特征向量，是通过聚合其邻居节点（如 `Domain`, `Certificate`）的特征向量来更新的。这意味着，一个 IP 的“画像”不再只看它自己，而是由“和它相关的所有事物”共同决定。GNN 能够自动学习如何权衡不同邻居（例如 `Certificate` 可能比 `GeoIP` 更重要）和不同数据模态，从而生成一个高度浓缩了融合信息的嵌入向量。














### 应用场景
1. 多源数据融合的资产探测方法。
	- 资产定位：例如，结合GIS数据、DNS数据、网络流量数据等多种来源的信息，提出了融合多源数据的资产定位方法，通过构建数据关联模型，充分挖掘不同数据源间的互补信息，提高资产定位的准确性和可靠性。
	- 资产发现：综合利用网络流量数据、DNS数据、安全设备日志等多源数据进行关联分析。例如，通过分析网络流量中的异常连接模式，找出可能隐藏的内部资产。同时,结合DNS解析记录,发现那些未公开备案但在网络中实际使用的域名和资产。特别是在云环境中，考虑到其上资源的动态性、弹性、底层不透明性，以及多租户环境下的复杂性，传统的静态资产探测方法往往难以适用或效果不佳。结合云服务商提供的云服务API，获取服务的实时信息，整合多种来源的数据，包括网络流量数据、系统日志数据、API调用数据等,  通过多维度数据分析来提高对服务的识别和监测能力。例如，结合网络流量的特征信息和系统日志中的事件记录，可以更准确地判断服务的状态和行为。
	- 抗虚假信息干扰：随着抗测绘方法的不断发展，如何有效识别和过滤虚假信息成为一个重要课题。综合利用网络流量数据、DNS数据、安全设备日志等多源数据进行关联分析。例如，通过分析网络流量中的异常连接模式，找出可能隐藏的内部资产。同时，结合DNS解析记录，发现那些未公开备案但在网络中实际使用的域名和资产。
2. 多源数据融合的漏洞与暴露面分析方法。通过融合多种数据源，包括系统日志、网络流量数据、漏洞扫描报告等，来更全面地进行漏洞分析。国内学术界部分研究认为知识图谱能够整合各类网络安全知识，包括漏洞信息、资产信息、攻击手法等，通过构建知识图谱并进行推理分析，可以更深入地理解网络中的安全状况。例如，山东大学的研究团队提出了一种基于知识图谱的多源数据融合方法，用于漏洞与暴露面分析。他们将不同来源的漏洞数据、资产数据以及安全事件数据整合到知识图谱中，利用图嵌入（图数据转化为低维的embedding）和知识推理技术，实现对漏洞关联分析和暴露面的精准定位。该方法在实际应用中取得了较好的效果，提高了对复杂网络环境下安全风险的感知能力。
## 智能化

# 问题与关键词
* [x] 网络安全态势感知、网络空间资产探测、网络空间测绘之间的区别和联系是什么？
* [x] 网络安全中攻击面与暴露面是否存在区别，如果存在，区别和联系是什么？
* [x] 网络空间资产探测中开放端口的主机上运营的”应用“和”服务“这两个关键词表征的意义是否存在区别，如果存在，区别和联系是什么？
* [x] 多源数据融合的具体应用案例。以网络空间搜索引擎为例，其是**如何**将IP、域名、物理定位、关联组织、端口和开放服务及应用、中间件甚至威胁情报等众多信息进行聚合、关联并展示给用户的？可以以真实的多源数据为例进行流程说明，并对其中应用到的技术进行介绍解释。
