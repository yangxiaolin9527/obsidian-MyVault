meta-learning 方法对比
1. MAML：需要记录节点信息，MAML has benefit of inductive bias without losing expressive power.(在不损失表达能力的前提前，具有归纳偏置的好处。)；但是二阶信息的利用需要较多的存储与计算资源，二层嵌套优化会带来不稳定性。
   收敛性与复杂度分析：Theoretical Convergence of Multi-Step Model-Agnostic Meta-Learning
   ![[Pasted image 20240729193958.png]]
   ![[Pasted image 20240729194152.png]]
	![[Pasted image 20240729193610.png]]
2. ANIL: 需要记录节点信息，相较于MAML，具有效率更高的元学习范式（在内循环中只更新部分参数），在不牺牲性能的前提下，可以显著提高学习速度。但是，仍然是ITD-based的方法，在内循环步数增大的情况下，计算与存储资源依然会随之线性增长。
   收敛性与复杂度分析:Convergence of Meta-Learning with Task-Speciﬁc Adaptation over Partial Parameters
   ![[Pasted image 20240729195715.png]]
   ![[Pasted image 20240729194910.png]]
   两种参数的收敛速率不同：shared parameter $\phi$, task-specific parameter $w$.
   